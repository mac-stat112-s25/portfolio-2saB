[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT112 Notebook",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "bw/bw-uni.html",
    "href": "bw/bw-uni.html",
    "title": "\n1  Univariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking univariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nCodelibrary(tidyverse)\nlibrary(viridis)\nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = viridis::viridis(1)) +\n  labs( \n    title = \"Distribution of Hike Elevations in High Peaks Region\",\n    x = \"Elevation (feet)\", \n    y = \"Number of hikes\",) +\n  theme_classic()\n\n\n\n\n\n\nCode#| fig-alt:\"This histogram displays the distribution of hike elevations in the High Peaks region. The x-axis represents elevation in feet, while the y-axis represents the number of hikes. The bars, filled in brown with black borders, show the frequency of hikes at different elevation levels, indicating whether most hikes occur at lower or higher elevations.\"",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-bi.html",
    "href": "bw/bw-bi.html",
    "title": "\n2  Bivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking bivariate visualization. The visualization will not perfect the first time but you are expected to improve it throughout the semester especially after covering advanced topics such as effective viz.\n\nCodelibrary(tidyverse)\nlibrary(ggthemes)  \n\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(color = \"red3\", shape = 16, alpha = 0.7) +  # Blue for colorblind-friendliness\n  labs(\n    title = \"Comparison of Republican Vote Share in 2016 vs. 2020 by County\",\n    x = \"Republican Vote Percentage (2016)\",\n    y = \"Republican Vote Percentage (2020)\",\n    caption = \"Counties with a high Republican vote share in 2016 generally maintained a similar share in 2020.\"\n  ) +\n  theme_minimal(base_size = 14) +  \n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5, margin = margin(b = 10)),  \n    plot.caption = element_text(size = 10, hjust = 0.5, margin = margin(t = 10)),  \n    plot.margin = margin(20, 20, 20, 20)  \n  )\n\n\n\n\n\n\nCode#| fig-alt: \"A scatter plot displaying the relationship between the percentage of Republican votes in 2016 and 2020 across U.S. counties. Each point represents a county, with its position showing the percentage of Republican votes in 2016 (x-axis) and 2020 (y-axis). The trend indicates how counties shifted in Republican support between the two elections.\"",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-tri.html",
    "href": "bw/bw-tri.html",
    "title": "\n3  Trivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking trivariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nCodelibrary(tidyverse)\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\") |&gt; \n  mutate(date = as.Date(date))  \nwoll &lt;- weather |&gt;\n  filter(location == \"Wollongong\") |&gt; \n  mutate(date = as.Date(date))  \n\n#View(weather)\n\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"#0072B2\", \"#E69F00\"), name = \"Will it Rain Tomorrow?\") + \n  labs(\n    title = \"Rain Prediction in Wollongong\",\n    subtitle = \"Relationship between rain today and rain tomorrow.\",\n    x = \"Did it Rain Today?\",\n    y = \"Probability of Rain\",\n    fill = \"Will it Rain Tomorrow?\",\n    caption = \"By: Thusa\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5, margin = margin(b = 10)),  \n    plot.caption = element_text(size = 10, hjust = 0, margin = margin(t = 10)),  \n    legend.position = \"right\",\n    plot.margin = margin(20, 20, 20, 20)\n  )\n\n\n\n\n\n\nCode#| fig-alt: \"A stacked bar chart showing the proportion of days in Wollongong where rain today is associated with rain tomorrow. The x-axis represents whether it rained today, and the bars are divided by color to show the proportion of rainy vs. non-rainy days the next day.\"\n\n#ggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  #geom_bar(position = \"fill\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Trivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-quad.html",
    "href": "bw/bw-quad.html",
    "title": "\n4  Quadvariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking quadvariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nCodelibrary(tidyverse)\nlibrary(palmerpenguins)\n\npenguins &lt;- drop_na(penguins)  \n\npenguins &lt;- penguins |&gt; \n  mutate(mass_category = cut(body_mass_g, \n                             breaks = c(2700, 3500, 4500, 5500, 6500),\n                             labels = c(\"Small\", \"Medium\", \"Large\", \"Extra Large\")))\n\nspecies_colors &lt;- c(\"#0072B2\", \"#E69F00\", \"#009E73\") \n# border_colors &lt;- c(\"#D55E00\", \"#56B4E9\", \"#CC79A7\", \"#009E73\")  \n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point(aes(fill = species, size = body_mass_g), \n             shape = 21, stroke = 1.5, alpha = 0.8) +  \n  scale_fill_manual(values = species_colors, name = \"Species\") +  \n#  scale_color_manual(values = border_colors, name = \"Body Mass Category\") +\n  scale_size_continuous(range = c(2, 6), name = \"Body Mass (g)\") + \n  labs(\n    title = \"A comparison of penguin species by bill length and depth\",\n    x = \"Bill Length (mm)\",\n    y = \"Bill Depth (mm)\",\n    caption = \"By: Thusa.\"\n  ) +\n  facet_wrap(~mass_category) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5, margin = margin(b = 10)),\n    plot.subtitle = element_text(size = 12, hjust = 0.5, margin = margin(b = 5)),\n    plot.caption = element_text(size = 10, hjust = 0, margin = margin(t = 10)),\n    legend.position = \"right\",\n    panel.grid.major = element_line(color = \"grey80\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\nCode#| fig-alt: \"A scatter plot displaying the relationship between penguin bill length and depth in millimetres across various specious. Species are shown by fill color (Adelie, Chinstrap, Gentoo), and body mass in grams is represented by size of plot and facet across four categories: Small, Medium, Large, and Extra Large.\"",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quadvariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-spatial.html",
    "href": "bw/bw-spatial.html",
    "title": "\n5  Spatial Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking spatial visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nCodelibrary(tidyverse)\nlibrary(mosaic)\nlibrary(RColorBrewer)\n\n#| fig-alt:\"This choropleth map visualizes the percentage of votes for the Republican candidate in the 2020 U.S. Presidential Election across states (excluding Washington, D.C.). States are color-coded into categories ranging from 0% to 100% Republican vote share, using a red-to-blue gradient. Darker red shades represent higher Republican vote percentages, while darker blue shades indicate lower percentages.\"\n\n##| fig-cap:\n\nstates_map &lt;- map_data(\"state\")\nelections_by_state &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\n\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = c(30, 35, 40, 45, 50, 55, 60, 65, 70),\n               labels = c(\"30-35\", \"36-40\", \"41-45\", \"46-50\", \n                          \"51-55\", \"56-60\", \"61-65\", \"66-70\"), \n               include.lowest = TRUE))\n\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  labs( \n    title = \"2020 U.S. Presidential Election: Republican Vote Percentage by State\",\n    caption = \"By: Thusa\") +\n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\") +\n  theme_map()",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-uni.html",
    "href": "ica/ica-uni.html",
    "title": "\n6  Univariate Viz\n",
    "section": "",
    "text": "6.0.1 Importance of Visualizations",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-uni.html#solutions",
    "href": "ica/ica-uni.html#solutions",
    "title": "\n6  Univariate Viz\n",
    "section": "\n6.1 Solutions",
    "text": "6.1 Solutions\n\nClick for Solutions\nExercise 1: Research Questions\n\nFor example: how many hikes are there in each category? are any categories more common than others?\nFor example: What’s a typical elevation? What’s the range in elevations?\nExercise 3: Bar Chart of Ratings - Part 1\n\nCodeggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\n\njust a blank canvas\nname of the dataset\nindicate which variable to plot on x-axis\n\naesthetics\nExercise 4: Bar Chart of Ratings - Part 2\n\nCode# Add a bar plot LAYER\nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n\nCode# Add meaningful axis labels\nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\nCode# FILL the bars with blue\nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\nCode# COLOR the outline of the bars in orange\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\nCode# Change the theme to a white background\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") + \n  theme_minimal()\n\n\n\n\n\n\n\nExercise 5: Bar Chart Follow-up\nPart a\n\nTo indicate we’re still adding layers to / modifying our plot.\nBars are the geometric elements we’re adding in this layer.\nlabels\n\nfill fills in the bars. color outlines the bars.\nPart b\nMost hikes are moderate, the fewest number are difficult.\nPart c\nI don’t like that the categories are alphabetical, not in order of difficulty level.\nExercise 6: Sad Bar Chart\nThere are too many different outcomes of elevation.\n\nCodeggplot(hikes, aes(x = elevation)) + \n  geom_bar()\n\n\n\n\n\n\n\nExercise 7: A Histogram of Elevation\nPart a\n\n6\n1 + 1 = 2\nPart b\nElevations range from roughly 3700 to 5500 feet. Elevations vary from hike to hike relatively normally (with a bell shape) around a typical elevation of roughly 4500 feet.\nExercise 9: Building Histograms - Part 2\n\nCode# Add a histogram layer\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram()\n\n\n\n\n\n\nCode# Outline the bars in white\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") \n\n\n\n\n\n\nCode# Fill the bars in blue\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"blue\") \n\n\n\n\n\n\nCode# Add axis labels\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\nCode# Change the width of the bins to 1000 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 1000) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\nCode# Change the width of the bins to 5 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 5) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\nCode# Change the width of the bins to 200 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 10: Histogram Follow-up\n\ngeom_histogram()\n\ncolor outlined the bars and fill filled them\neasier to distinguish between the bars\nchanged the bin width\nwe lump too many hikes together and lose track of the nuances\nwe don’t lump enough hikes together and lose track of the bigger picture trends\nExercise 11: Density plots\n\nCodeggplot(hikes, aes(x = elevation)) +\n geom_density(color = \"blue\", fill = \"orange\")\n\n\n\n\n\n\n\nExercise 13: Code = Communication\n\nClarifies that the subsequent lines are a continuation of the first. That is, we’re not done with the plot yet. These lines are all part of the same idea.\nThis is like a run-on sentence. It’s tough to track the distinct steps that go into building the plot.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html",
    "href": "ica/ica-bi.html",
    "title": "\n7  Bivariate Viz\n",
    "section": "",
    "text": "7.1 Exercise 0\nCode# Load data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\nlibrary(tidyverse)\n#View(elections)\n# Check it out\nhead(elections)\n\n  state_name state_abbr historical    county_name county_fips total_votes_20\n1    Alabama         AL        red Autauga County        1001          27770\n2    Alabama         AL        red Baldwin County        1003         109679\n3    Alabama         AL        red Barbour County        1005          10518\n4    Alabama         AL        red    Bibb County        1007           9595\n5    Alabama         AL        red  Blount County        1009          27588\n6    Alabama         AL        red Bullock County        1011           4613\n  repub_pct_20 dem_pct_20 winner_20 total_votes_16 repub_pct_16 dem_pct_16\n1        71.44      27.02     repub          24661        73.44      23.96\n2        76.17      22.41     repub          94090        77.35      19.57\n3        53.45      45.79     repub          10390        52.27      46.66\n4        78.43      20.70     repub           8748        76.97      21.42\n5        89.57       9.57     repub          25384        89.85       8.47\n6        24.84      74.70       dem           4701        24.23      75.09\n  winner_16 total_votes_12 repub_pct_12 dem_pct_12 winner_12 total_population\n1     repub          23909        72.63      26.58     repub            54907\n2     repub          84988        77.39      21.57     repub           187114\n3     repub          11459        48.34      51.25       dem            27321\n4     repub           8391        73.07      26.22     repub            22754\n5     repub          23980        86.49      12.35     repub            57623\n6       dem           5318        23.51      76.31       dem            10746\n  percent_white percent_black percent_asian percent_hispanic per_capita_income\n1            76            18             1                2             24571\n2            83             9             1                4             26766\n3            46            46             0                5             16829\n4            75            22             0                2             17427\n5            88             1             0                8             20730\n6            22            71             0                6             18628\n  median_rent median_age\n1         668       37.5\n2         693       41.5\n3         382       38.3\n4         351       39.4\n5         403       39.6\n6         276       39.6\nCodeggplot(elections, aes(x = repub_pct_16, y = repub_pct_20) ) +\n  geom_point()\nCode# Set up the plotting frame\n# How does this differ than the frame for our histogram of repub_pct_20 alone?\n# In a histogram the y axis is a count.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-1",
    "href": "ica/ica-bi.html#exercise-1",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.2 Exercise 1",
    "text": "7.2 Exercise 1\n\nCodeggplot(elections, aes(x = repub_pct_20)) +\n  geom_histogram()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-2",
    "href": "ica/ica-bi.html#exercise-2",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.3 Exercise 2",
    "text": "7.3 Exercise 2\n\nCode# Add a layer of points for each county\n# Take note of the geom!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n\n\n\n\n\n\nCode# Change the shape of the points\n# What happens if you change the shape to another number? Creates different kind of shapes\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(shape = 10)\n\n\n\n\n\n\n\n\nCode# YOU TRY: Modify the code to make the points \"orange\"\n# NOTE: Try to anticipate if \"color\" or \"fill\" will be useful here. Then try both.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(color = \"orange\", fill = \"black\")\n\n\n\n\n\n\n\n\nCode# Add a layer that represents each county by the state it's in\n# Take note of the geom and the info it needs to run!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_text(aes(label = state_abbr))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-3",
    "href": "ica/ica-bi.html#exercise-3",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.4 Exercise 3",
    "text": "7.4 Exercise 3\n\n7.4.0.1 Summarize the relationship between the Republican support in 2020 and 2016. Be sure to comment on:\nthe strength of the relationship (weak/moderate/strong) - STRONG\nthe direction of the relationship (positive/negative) - POSITIVE\noutliers (in what state do counties deviate from the national trend? Any ideas why this might be the case?) - TX because they may have a big county that votes for democrats that changes the mean votes for republicants, i.e. more counties started voting for republican\nExercise 4\n\nCodeggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\n\nCode# Construct a new plot that contains the model smooth but does not include the individual point glyphs\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_smooth()\n\n\n\n\n\n\n\n\nCode# By default, geom_smooth() adds a smooth, localized model line. To examine the “best” linear model, we can specify method = \"lm\". It’s pretty similar in this example!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-5",
    "href": "ica/ica-bi.html#exercise-5",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.5 Exercise 5",
    "text": "7.5 Exercise 5\n\nCode# Scatterplot of repub_pct_20 vs median_rent\nggplot(elections, aes(y = repub_pct_20, x = median_age)) +\n  geom_point()\n\n\n\n\n\n\nCode# Has a moderate positive correlation\n\n\n# Scatterplot of repub_pct_20 vs median_age\nggplot(elections, aes(y = repub_pct_20, x = median_rent)) +\n  geom_point()\n\n\n\n\n\n\nCode# Has a weak negative correlation\n\n#Of the 2, median_rent is a better predictor.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-6",
    "href": "ica/ica-bi.html#exercise-6",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.6 Exercise 6",
    "text": "7.6 Exercise 6\n\nCodeggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_point()\n\n\n\n\n\n\nCode# This is not a good plot because it does not show any relationship and points are plotted against each other.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-7",
    "href": "ica/ica-bi.html#exercise-7",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.7 Exercise 7",
    "text": "7.7 Exercise 7\n\nCode# Side-by-side violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n\n\n\n\n\n\nCode# Side-by-side boxplots (defined below)\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nSummarize what you’ve learned about the 2020 Republican county-level support within and between red/purple/blue states.\n\nThere is high support in descending order from red to purple to blue states",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-8",
    "href": "ica/ica-bi.html#exercise-8",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.8 Exercise 8",
    "text": "7.8 Exercise 8\n\nCodeggplot(elections, aes(x = repub_pct_20)) +\n  geom_density()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-9",
    "href": "ica/ica-bi.html#exercise-9",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.9 Exercise 9",
    "text": "7.9 Exercise 9\n\nCode# Name two \"bad\" things about this plot - density plots are not complete and the color code does not match\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n\n\n\n\n\n\nCode# What does scale_fill_man - scale_fill_manual determines what colors to use for the fill categories\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\n\nCode# What does alpha = 0.5 do? *make it slightly transparent*\n# Play around with different values of alpha, between 0 and 1\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\n\nCode# What does facet_wrap do?! - *presents the density plots in separate graphs*\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n\n\nCode# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible? - *does not show everything in each categories*\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-10",
    "href": "ica/ica-bi.html#exercise-10",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.10 Exercise 10",
    "text": "7.10 Exercise 10\nWe’ve now learned 3 (of many) ways to visualize the relationship between a quantitative and categorical variable: side-by-side violins, boxplots, and density plots.\nWhich do you like best? Density Plots\nWhat is one pro of density plots relative to boxplots? Shows the beginning and end, has better visualization of data distribution\nWhat is one con of density plots relative to boxplots? They can be less clear when comparing multiple distributions at once",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-11",
    "href": "ica/ica-bi.html#exercise-11",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.11 Exercise 11",
    "text": "7.11 Exercise 11\n\nCode# Plot 1: adjust this to recreate the top plot\nggplot(elections, aes(x = historical)) +\n  geom_bar()\n\n\n\n\n\n\nCodeggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nCode# Plot 2: adjust this to recreate the bottom plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-12",
    "href": "ica/ica-bi.html#exercise-12",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.12 Exercise 12",
    "text": "7.12 Exercise 12\n\nCode# A stacked bar plot\n# How are the \"historical\" and \"winner_20\" variables mapped to the plot, i.e. what roles do they play? Historical is X-axis while winner_20 is the scale\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nCode# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n\n\nCode# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nCode# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nName one pro and one con of using the “proportional bar plot” instead of one of the other three options. - Pro: Easy to compare the two categories - Con: Cannot tell how many points fall into each category\nFavourite graph is side-by-side bar plot because its easy to interpret.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercise-13",
    "href": "ica/ica-bi.html#exercise-13",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.13 Exercise 13",
    "text": "7.13 Exercise 13\n\nCodeweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\n\n\nCode# How do 3pm temperatures (temp3pm) differ by location\n\n\n\nCode# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\n\n\n\nCode# How do the number of rainy days (raintoday) differ by location?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#optional-exercise-1-many-categories",
    "href": "ica/ica-bi.html#optional-exercise-1-many-categories",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.14 Optional Exercise 1: Many Categories",
    "text": "7.14 Optional Exercise 1: Many Categories\n\nCodeggplot(elections, aes(x = repub_pct_20, fill = state_abbr)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\nCode# Reflect on why this is bad. \n\n\n\nCodeggplot(elections, aes(x = repub_pct_20)) + \n  geom_density(alpha = 0.5) + \n  facet_wrap(~ state_abbr)\n\n\n\n\n\n\nCode# This is also bad\n\n\n\nCode# Install ggridges package\nlibrary(ggridges)\n\n# Make our first joy plot\n# THINK: What DON'T you like about this? Its too crowded and not easy to read\nggplot(elections, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_density_ridges()\n\n\n\n\n\n\n\n\nCode# Let's put the states in order by Republican support, not alphabet\n# How do you think fct_reorder works? We'll learn about this later in the semester.\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_density_ridges(alpha = 0.5)\n\n\n\n\n\n\n\n\nCode# YOUR TURN: color/fill the ridges according to a state's historical voting patterns \n# and add meaningful axis labels\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20), fill = historical)) + \n  geom_density_ridges(alpha = 0.4) + \n  labs(y = \"state\", x = \"2020 Republican support (%)\") + \n  scale_fill_manual(values = c(\"yellow\", \"green\", \"pink\"))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#optional-exercise-2-total-outcomes-by-state",
    "href": "ica/ica-bi.html#optional-exercise-2-total-outcomes-by-state",
    "title": "\n7  Bivariate Viz\n",
    "section": "\n7.15 Optional Exercise 2: Total Outcomes by State",
    "text": "7.15 Optional Exercise 2: Total Outcomes by State\n\nCodeelections_by_state &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nggplot(elections_by_state, aes(y = repub_pct_20, x = repub_pct_16)) + \n  geom_point()\n\n\n\n\n\n\n\n\nCode# Create a \"scatterplot\" of state_abbr (y-axis) by 2020 Republican support on the x-axis\n# Color the points red\n\nggplot(elections_by_state, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\nCode# Reorder the states in terms of their 2020 Republican support (not alphabet)\n\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\nCode# Add ANOTHER layer of points for the 2016 outcomes\n# What info does this new geom_point() layer need to run?\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\") + \n  geom_point(aes(x = repub_pct_16, y = state_abbr))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html",
    "href": "ica/ica-multi.html",
    "title": "\n8  Mulivariate Viz\n",
    "section": "",
    "text": "8.1 Exercise 1\nCode# Part a\n# Construct a plot of how the average sat scores vary from state to state. (Just use 1 variable – sat not State!)\nggplot(education, aes(x = sat)) + \n  geom_density()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercise-1",
    "href": "ica/ica-multi.html#exercise-1",
    "title": "\n8  Mulivariate Viz\n",
    "section": "",
    "text": "8.1.0.1 Part b\n\n8.1.0.1.1 Summarize your observations from the plot. Comment on the basics: range, typical outcomes, shape. (Any theories about what might explain this non-normal shape?)\nThey range from 800 to 1000",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercise-2",
    "href": "ica/ica-multi.html#exercise-2",
    "title": "\n8  Mulivariate Viz\n",
    "section": "\n8.2 Exercise 2",
    "text": "8.2 Exercise 2\n\n8.2.0.1 Part a\n\nCode# Construct a plot of sat vs expend\n# Include a \"best fit linear regression model\" (HINT: method = \"lm\")\nggplot(education, aes(x=sat, y=expend)) +\n  geom_smooth(method =\"lm\")\n\n\n\n\n\n\n\n\nCode# Construct a plot of sat vs salary\n# Include a \"best fit linear regression model\" (HINT: method = \"lm\")\nggplot(education, aes(x=sat, y=salary)) +\n  geom_smooth(method =\"lm\")\n\n\n\n\n\n\n\n\n8.2.0.2 Part b\n\n8.2.0.2.1 What are the relationship trends between SAT scores and spending? Is there anything that surprises you?\nThe higher the scores the lower the salary that teachers received.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercise-3",
    "href": "ica/ica-multi.html#exercise-3",
    "title": "\n8  Mulivariate Viz\n",
    "section": "\n8.3 Exercise 3",
    "text": "8.3 Exercise 3\n\n8.3.0.0.1 Construct one visualization of the relationship of sat with salary and expend. HINT: Start with just 2 variables and tweak that code to add the third variable. Try out a few things!\n\nCodeggplot(education, aes(x = sat, y = expend, color = salary)) +\n  geom_point()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercise-4",
    "href": "ica/ica-multi.html#exercise-4",
    "title": "\n8  Mulivariate Viz\n",
    "section": "\n8.4 Exercise 4",
    "text": "8.4 Exercise 4\n\nCodeggplot(education, aes(y = sat, x = salary, color = cut(expend, 2))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\n\n\n\n8.4.0.0.1 What happens if you change “2” to “3”? -\n\nincreases the number of lines of continuous lines of the expend variable, it also changes the color",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercise-5",
    "href": "ica/ica-multi.html#exercise-5",
    "title": "\n8  Mulivariate Viz\n",
    "section": "\n8.5 Exercise 5",
    "text": "8.5 Exercise 5\n\n8.5.0.1 Part a\nBuild a univariate viz of fracCat to better understand how many states fall into each category.\n\nCodeggplot(education, aes(x = fracCat)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n8.5.0.2 Part b\nBuild 2 bivariate visualizations that demonstrate the relationship between sat and fracCat. What story does your graphic tell and why does this make contextual sense?\n\nCodeggplot(education, aes(x = sat, fill = fracCat)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n8.5.0.3 Part c\nMake a trivariate visualization that demonstrates the relationship of sat with expend AND fracCat. Highlight the differences in fracCat groups through color AND unique trend lines. What story does your graphic tell? Does it still seem that SAT scores decrease as spending increases?\n\nCodeggplot(education, aes(x = expend, y = sat, color = fracCat)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n8.5.0.4 Part d\nPutting all of this together, explain this example of Simpson’s Paradox. That is, why did it appear that SAT scores decrease as spending increases even though the opposite is true?\n\nThere is selected participation in states where there is lowere expenditure therefore produces higher results.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html",
    "href": "ica/ica-spatial.html",
    "title": "\n9  Spatial Viz\n",
    "section": "",
    "text": "9.1 Exercise 1\nCodefave_places &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/our_fave_places.csv\")\n\n# Check it out\nhead(fave_places)\n\n  latitude longitude\n1       59        18\n2       45       -93\n3       33      -117\n4       40       116\n5       40       106\n6       37      -122",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-1",
    "href": "ica/ica-spatial.html#exercise-1",
    "title": "\n9  Spatial Viz\n",
    "section": "",
    "text": "9.1.0.1 Part a\n\nCode# Load the leaflet package\nlibrary(leaflet)\nlibrary(tidyverse)\n\n# Just a plotting frame\nleaflet(data = fave_places)\n\n\n\n\n\n\nCode# Now what do we have?\n# A frame with a map\nleaflet(data = fave_places) |&gt; \n  addTiles()\n\n\n\n\n\n\nCode# Now what do we have?\n# longitude and latitude refer to the variables in our data\n# We now have a map with points plotted based on longitude & latitude.\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers(lng = ~longitude, lat = ~latitude)\n\n\n\n\n\n\nCode# Since we named them \"longitude\" and \"latitude\", the function\n# automatically recognizes these variables. No need to write them!\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\n\n9.1.0.2 Part b\n\n9.1.0.2.1 PLAY AROUND! This map is interactive. Zoom in on one location. Keep zooming – what level of detail can you get into? How does that detail depend upon where you try to zoom in (thus what are the limitations of this tool)?\n\nThe zooming is limited to geographical contours.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-2",
    "href": "ica/ica-spatial.html#exercise-2",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.2 Exercise 2",
    "text": "9.2 Exercise 2\n\nCode# Load package needed to change color\nlibrary(gplots)\n\n# We can add colored circles instead of markers at each location\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addCircles(color = col2hex(\"red\"))\n\n\n\n\n\n\nCode# We can change the background\n# Mark locations with yellow dots\n# And connect the dots, in their order in the dataset, with green lines\n# (These green lines don't mean anything here, but would if this were somebody's travel path!)\nleaflet(data = fave_places) |&gt;\n  addProviderTiles(\"USGS\") |&gt;\n  addCircles(weight = 10, opacity = 1, color = col2hex(\"yellow\")) |&gt;\n  addPolylines(\n    lng = ~longitude,\n    lat = ~latitude,\n    color = col2hex(\"green\")\n  )",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-3",
    "href": "ica/ica-spatial.html#exercise-3",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.3 Exercise 3",
    "text": "9.3 Exercise 3\n\n9.3.1 Part a\n\nCode# Import starbucks location data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\n\n\n\nCode# Don't worry about the syntax\nstarbucks_mn &lt;- starbucks |&gt;   \n  filter(Country == \"US\", State.Province == \"MN\")\n\n\n\n9.3.1.0.1 Create a leaflet map of the Starbucks locations in Minnesota. Keep it simple – go back to Exercise 1 for an example.\n\nCodeleaflet(data = starbucks_mn) |&gt; \n  addTiles() |&gt; \n  addCircles(color = col2hex(\"blue\"))\n\n\n\n\n\n\n9.3.1.1 Part b\n\n9.3.1.1.1 Let’s start with the ggplot() tools we already know. Construct a scatterplot of all starbucks locations, not just those in Minnesota, with:\nLatitude and Longitude coordinates (which goes on the y-axis?!) Make the points transparent (alpha = 0.2) and smaller (size = 0.2)\n\nCodeggplot(starbucks, aes( x = Longitude, y = Latitude)) +\n  geom_point( alpha = 0.2, size = 0.2)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-4",
    "href": "ica/ica-spatial.html#exercise-4",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.4 Exercise 4",
    "text": "9.4 Exercise 4\n\n9.4.0.1 Part a\n\nCode# Load the package\nlibrary(rnaturalearth)\n\n# Get info about country boundaries across the world\n# in a \"sf\" or simple feature format\nworld_boundaries &lt;- ne_countries(returnclass = \"sf\")\n\n\n\n9.4.0.2 Part b\n\nCode# What does this code produce?\n# What geom are we using for the point map?\nggplot(world_boundaries) + \n  geom_sf()\n\n\n\n\n\n\n\n\nCode# Load package needed to change map theme\nlibrary(mosaic)\n\n# Add a point for each Starbucks\n# NOTE: The Starbucks info is in our starbucks data, not world_boundaries\n# How does this change how we use geom_point?!\nggplot(world_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3, size = 0.2, color = \"darkgreen\"\n  ) +\n  theme_map()\n\n\n\n\n\n\n\n\n9.4.1 Part c\n\n9.4.1.0.1 Summarize what you learned about Starbucks from this map.\n\nStarbucks is a multinational franchise that is concentrated in the US, South America and East Asia.\nThere are some branches in South America, Australia and Africa but not many of them.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-5",
    "href": "ica/ica-spatial.html#exercise-5",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.5 Exercise 5",
    "text": "9.5 Exercise 5\n\n9.5.0.1 Part a\nData on Starbucks for only Canada, Mexico, and the US, labeled as “CA”, “MX”, “US” in the starbucks data.\n\nCode# We'll learn this syntax soon! Don't worry about it now.\nstarbucks_cma &lt;- starbucks |&gt; \n  filter(Country %in% c('CA', 'MX', 'US'))\n\n\n\nCodecma_boundaries &lt;- ne_states(\n  country = c(\"canada\", \"mexico\", \"united states of america\"),\n  returnclass = \"sf\")\n\n\n\n9.5.0.2 Part b\n\n9.5.0.2.1 Make the map\n\nCode# Just the boundaries\nggplot(cma_boundaries) + \n  geom_sf()\n\n\n\n\n\n\n\n\nCode# Add the points\n# And zoom in\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50)) +\n  theme_map()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-6",
    "href": "ica/ica-spatial.html#exercise-6",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.6 Exercise 6",
    "text": "9.6 Exercise 6\n\n9.6.0.1 Part a\n\nCodestarbucks_midwest &lt;- starbucks |&gt; \n  filter(State.Province %in% c(\"MN\", \"ND\", \"SD\", \"WI\"))\n\n\n\nCode# Load packages\nlibrary(sf)\nlibrary(maps)\n\n# Get the boundaries\nmidwest_boundaries &lt;- st_as_sf(\n  maps::map(\"county\",\n            region = c(\"minnesota\", \"wisconsin\", \"north dakota\", \"south dakota\"), \n            fill = TRUE, plot = FALSE))\n\n# Check it out\nhead(midwest_boundaries)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -96.81268 ymin: 45.05167 xmax: -93.01397 ymax: 48.53526\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\n                                     ID                           geom\nminnesota,aitkin       minnesota,aitkin MULTIPOLYGON (((-93.03689 4...\nminnesota,anoka         minnesota,anoka MULTIPOLYGON (((-93.51817 4...\nminnesota,becker       minnesota,becker MULTIPOLYGON (((-95.14537 4...\nminnesota,beltrami   minnesota,beltrami MULTIPOLYGON (((-95.58655 4...\nminnesota,benton       minnesota,benton MULTIPOLYGON (((-93.77027 4...\nminnesota,big stone minnesota,big stone MULTIPOLYGON (((-96.10794 4...\n\n\n\n9.6.0.2 Part b\n\nCodeggplot(midwest_boundaries) + \n   geom_sf() + \n   geom_point(\n     data = starbucks_midwest,\n     aes(x = Longitude, y = Latitude),\n     alpha = 0.7,\n     size = 0.2, \n     color = 'darkgreen'\n   ) + \n   theme_map()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-7",
    "href": "ica/ica-spatial.html#exercise-7",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.7 Exercise 7",
    "text": "9.7 Exercise 7\n\n9.7.0.1 Part a\n\nCode# Point map (we made this earlier)\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\n\n9.7.0.2 Part b\n\nCode# What changed in the plot?\n# What changed in our code?!\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_density_2d(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\n\n9.7.0.3 Part c\n\nCodeelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n\nCode# Don't worry about the code!\n\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-8",
    "href": "ica/ica-spatial.html#exercise-8",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.8 Exercise 8",
    "text": "9.8 Exercise 8\n\n9.8.0.1 Part a\n\nCode# Get the latitude and longitude coordinates of state boundaries\nstates_map &lt;- map_data(\"state\")\n\n# Check it out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\nCodehead(elections_by_state) \n\n   state_name state_abbr repub_pct_20 repub_20_categories\n1     alabama         AL        62.03               60-64\n2    arkansas         AR        62.40               60-64\n3     arizona         AZ        49.06               45-49\n4  california         CA        34.33               30-34\n5    colorado         CO        41.90               40-44\n6 connecticut         CT        39.21               35-39\n\n\n\n9.8.0.2 Part b\n\nCode# Note where the dataset, elections_by_state, is used\n# Note where the background map, states_map, is used\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() \n\n\n\n\n\n\n\n\nCode# Make it nicer!\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_gradientn(name = \"% Republican\", colors = c(\"blue\", \"purple\", \"red\"), values = scales::rescale(seq(0, 100, by = 5)))\n\n\n\n\n\n\n\n\nCodeggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map()\n\n\n\n\n\n\n\n\nCode# Load package needed for refining color palette\nlibrary(RColorBrewer)\n\n# Now fix the colors\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n\n\n\n9.8.0.3 Part c\n\nCode# Get only the starbucks data from the US\nstarbucks_us &lt;- starbucks |&gt; \n  filter(Country == \"US\")\n\n# Map it\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  geom_point(\n    data = starbucks_us,\n    aes(x = Longitude, y = Latitude),\n    size = 0.05,\n    alpha = 0.2,\n    inherit.aes = FALSE\n  ) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n\n\n\n9.8.0.4 Part d\n\n9.8.0.4.0.1 We used geom_sf() for point maps. What geom do we use for choropleth maps?\n\ngeom_sf()\ngeom_polygon",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-9",
    "href": "ica/ica-spatial.html#exercise-9",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.9 Exercise 9",
    "text": "9.9 Exercise 9\n\n9.9.0.1 Part a\n\nCode# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\nCodehead(elections_by_counties)\n\n  state_name state_abbr    county_name county_fips repub_pct_20 median_age\n1    Alabama         AL Autauga County        1001        71.44       37.5\n2    Alabama         AL Baldwin County        1003        76.17       41.5\n3    Alabama         AL Barbour County        1005        53.45       38.3\n4    Alabama         AL    Bibb County        1007        78.43       39.4\n5    Alabama         AL  Blount County        1009        89.57       39.6\n6    Alabama         AL Bullock County        1011        24.84       39.6\n  median_rent repub_20_categories\n1         668               70-79\n2         693               70-79\n3         382               50-59\n4         351               70-79\n5         403               80-89\n6         276               20-29\n\n\n\nCode# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\n\n\n9.9.0.2 Part b\n\n9.9.0.2.0.1 Now map Republican support by county. Let’s go straight to the discretized repub_20_categories variable, and a good color scale.\n\nCodeggplot(elections_by_counties, aes(map_id = county_fips, fill = repub_20_categories)) +\n  geom_map(map = county_map) +\n  scale_fill_manual(values = rev(brewer.pal(10, \"RdBu\")), name = \"% Republican\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercise-10",
    "href": "ica/ica-spatial.html#exercise-10",
    "title": "\n9  Spatial Viz\n",
    "section": "\n9.10 Exercise 10",
    "text": "9.10 Exercise 10\n\n9.10.0.0.0.1 Construct county-level maps of median_rent and median_age.\n\nCodeggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n  geom_map(map = county_map) +\n  # scale_fill_manual(values = rev(brewer.pal(10, \"RdBu\")), name = \"% Median Rent\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()\n\n\n\n\n\n\nCodeggplot(elections_by_counties, aes(map_id = county_fips, fill = median_age)) +\n  geom_map(map = county_map) +\n  # scale_fill_manual(values = rev(brewer.pal(10, \"RdBu\")), name = \"% Median Rent\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html",
    "href": "ica/ica-effective.html",
    "title": "\n10  Effective Viz\n",
    "section": "",
    "text": "10.1 Exercise 1: Professionalism\nCodeweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\") |&gt; \n  mutate(date = as.Date(date)) \n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#exercise-1-professionalism",
    "href": "ica/ica-effective.html#exercise-1-professionalism",
    "title": "\n10  Effective Viz\n",
    "section": "",
    "text": "10.1.0.0.1 Part a\n\nCodeggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() + \n  labs(x = \"A\", y = \"B\", title = \"C\", color = \"D\")",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html",
    "href": "ica/ica-wrangling.html",
    "title": "\n11  Wrangling\n",
    "section": "",
    "text": "11.1 Exercise 1\nCode# Define elections_small\nelections_small &lt;- elections|&gt;\n  select(state_name, county_name, total_votes_20, repub_pct_20, dem_pct_20, total_votes_16, dem_pct_16)\n\n# Check out the first 6 rows to confirm your code did what you think it did!\n\n#head(elections_small)\n#View(elections_small)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-2",
    "href": "ica/ica-wrangling.html#exercise-2",
    "title": "\n11  Wrangling\n",
    "section": "\n11.2 Exercise 2",
    "text": "11.2 Exercise 2\n\nCode# Keep only data on counties in Hawaii\nelections_small |&gt;\n  filter(state_name %in% c(\"Hawaii\"))\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1     Hawaii   Hawaii County          87814        30.63      66.88\n2     Hawaii Honolulu County         382114        35.66      62.51\n3     Hawaii    Kauai County          33497        34.58      63.36\n4     Hawaii     Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          64865      63.61\n2         285683      61.48\n3          26335      62.49\n4          51942      64.45\n\n\n\nCode# What does this do?\n elections_small |&gt; \n   filter(state_name %in% c(\"Hawaii\", \"Delaware\"))\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1   Delaware       Kent County          87025        47.12      51.19\n2   Delaware New Castle County         287633        30.72      67.81\n3   Delaware     Sussex County         129352        55.07      43.82\n4     Hawaii     Hawaii County          87814        30.63      66.88\n5     Hawaii   Honolulu County         382114        35.66      62.51\n6     Hawaii      Kauai County          33497        34.58      63.36\n7     Hawaii       Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          74253      44.91\n2         261468      62.30\n3         105814      37.17\n4          64865      63.61\n5         285683      61.48\n6          26335      62.49\n7          51942      64.45\n\nCode# Keeps information on Hawaii and Delaware\n\n\n\nCode# Keep only data on counties where the Republican got MORE THAN 93.97% of the vote in 2020\n# THINK: What variable is relevant here?\nelections_small |&gt; \n   filter(repub_pct_20 &gt; 93.7)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Montana Garfield County            813        93.97       5.04\n2      Texas   Borden County            416        95.43       3.85\n3      Texas     King County            159        94.97       5.03\n4      Texas  Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            715       4.76\n2            365       8.49\n3            159       3.14\n4            550       3.64\n\n\n\nCode# Keep only data on counties where the Republican got AT LEAST 93.97% of the vote in 2020\n# This should have 1 more row (observation) than your answer above\nelections_small |&gt; \n   filter(repub_pct_20 &gt;= 93.7)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Montana Garfield County            813        93.97       5.04\n2      Texas   Borden County            416        95.43       3.85\n3      Texas     King County            159        94.97       5.03\n4      Texas  Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            715       4.76\n2            365       8.49\n3            159       3.14\n4            550       3.64\n\n\n\nCode# Keep only data on counties in Texas where the Democrat got more than 65% of the vote in 2020\n# Do this 2 ways.\n# Method 1: 2 filters with 1 condition each\nelections_small |&gt; \n  filter(dem_pct_20 &gt; 65) |&gt; \n  filter(state_name %in% c(\"Texas\"))\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\nCode# Method 2: 1 filter with 2 conditions\nelections_small |&gt; \n  filter(dem_pct_20 &gt; 65, state_name %in% c(\"Texas\"))\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-3",
    "href": "ica/ica-wrangling.html#exercise-3",
    "title": "\n11  Wrangling\n",
    "section": "\n11.3 Exercise 3",
    "text": "11.3 Exercise 3\n\nCode# Arrange the counties in elections_small from lowest to highest percentage of 2020 Republican support\n# Print out just the first 6 rows\n elections_small |&gt; \n   arrange(repub_pct_20) |&gt; \n   head()\n\n            state_name            county_name total_votes_20 repub_pct_20\n1 District of Columbia   District of Columbia         344356         5.40\n2             Maryland Prince George's County         424855         8.73\n3             Maryland         Baltimore city         237461        10.69\n4             Virginia        Petersburg city          14118        11.22\n5             New York        New York County         694904        12.26\n6           California   San Francisco County         443458        12.72\n  dem_pct_20 total_votes_16 dem_pct_16\n1      92.15         280272      92.85\n2      89.26         351091      89.33\n3      87.28         208980      85.44\n4      87.75          13717      87.52\n5      86.78         591368      87.17\n6      85.27         365295      85.53\n\n\n\nCode# Arrange the counties in elections_small from highest to lowest percentage of 2020 Republican support\n# Print out just the first 6 rows\n elections_small |&gt; \n   arrange(desc(repub_pct_20)) |&gt; \n   head()\n\n  state_name      county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas   Roberts County            550        96.18       3.09\n2      Texas    Borden County            416        95.43       3.85\n3      Texas      King County            159        94.97       5.03\n4    Montana  Garfield County            813        93.97       5.04\n5      Texas Glasscock County            653        93.57       5.97\n6   Nebraska     Grant County            402        93.28       4.98\n  total_votes_16 dem_pct_16\n1            550       3.64\n2            365       8.49\n3            159       3.14\n4            715       4.76\n5            602       5.65\n6            394       5.08",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-4",
    "href": "ica/ica-wrangling.html#exercise-4",
    "title": "\n11  Wrangling\n",
    "section": "\n11.4 Exercise 4",
    "text": "11.4 Exercise 4\n\n11.4.0.1 Part a\n\nCode# What did this code do?\n elections_small |&gt; \n   mutate(diff_20 = repub_pct_20 - dem_pct_20) |&gt; \n   head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 diff_20\n1          24661      23.96   44.42\n2          94090      19.57   53.76\n3          10390      46.66    7.66\n4           8748      21.42   57.73\n5          25384       8.47   80.00\n6           4701      75.09  -49.86\n\nCode# Gives the difference between the 2 percentages and creates a new column for it.\n\n\n\nCode# What did this code do?\n elections_small |&gt; \n   mutate(repub_votes_20 = round(total_votes_20 * repub_pct_20/100)) |&gt; \n   head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_votes_20\n1          24661      23.96          19839\n2          94090      19.57          83542\n3          10390      46.66           5622\n4           8748      21.42           7525\n5          25384       8.47          24711\n6           4701      75.09           1146\n\nCode# Gives a number of the total republican votes. \n\n\n\nCode# What did this code do?\n elections_small |&gt; \n   mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt; \n   head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_win_20\n1          24661      23.96         TRUE\n2          94090      19.57         TRUE\n3          10390      46.66         TRUE\n4           8748      21.42         TRUE\n5          25384       8.47         TRUE\n6           4701      75.09        FALSE\n\nCode# It created a new column that shows the counties which the republicans won in 2020.\n\n\n\n11.4.0.2 Part b\n\nCode# You try\n# Define a variable that calculates the change in Dem support in 2020 vs 2016\nelections_small |&gt; \n  mutate(dem_diff = dem_pct_20 - dem_pct_16) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 dem_diff\n1          24661      23.96     3.06\n2          94090      19.57     2.84\n3          10390      46.66    -0.87\n4           8748      21.42    -0.72\n5          25384       8.47     1.10\n6           4701      75.09    -0.39\n\n\n\nCode# You try\n# Define a variable that determines whether the Dem support was higher in 2020 than in 2016 (TRUE/FALSE)\nelections_small |&gt; \n  mutate(dem_support = dem_pct_20 &gt; dem_pct_16) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 dem_support\n1          24661      23.96        TRUE\n2          94090      19.57        TRUE\n3          10390      46.66       FALSE\n4           8748      21.42       FALSE\n5          25384       8.47        TRUE\n6           4701      75.09       FALSE",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-5",
    "href": "ica/ica-wrangling.html#exercise-5",
    "title": "\n11  Wrangling\n",
    "section": "\n11.5 Exercise 5",
    "text": "11.5 Exercise 5\n\n11.5.0.1 Part a\n\nCode elections_small |&gt; \n   filter(state_name == \"Wisconsin\",\n          repub_pct_20 &lt; dem_pct_20) |&gt; \n   arrange(desc(total_votes_20)) |&gt; \n   head()\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1  Wisconsin  Milwaukee County         458971        29.27      69.13\n2  Wisconsin       Dane County         344791        22.85      75.46\n3  Wisconsin       Rock County          85360        43.51      54.66\n4  Wisconsin  La Crosse County          67884        42.25      55.75\n5  Wisconsin Eau Claire County          58275        43.49      54.26\n6  Wisconsin    Portage County          40603        47.53      50.31\n  total_votes_16 dem_pct_16\n1         434970      66.44\n2         304729      71.38\n3          75043      52.42\n4          62785      51.61\n5          54080      50.43\n6          38123      48.59\n\nCode# The data is shown just for Wisconsin for counties that had a republican vote percentage less than the percentage of democrats and was arranged in descending order of the total votes. \n\n\n\n11.5.0.2 Part b\n\nCode# Now try it. Change the order of filter and arrange below.\n elections_small |&gt; \n  arrange(desc(total_votes_20)) |&gt; \n   filter(state_name == \"Wisconsin\",\n          repub_pct_20 &lt; dem_pct_20) |&gt; \n   head()\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1  Wisconsin  Milwaukee County         458971        29.27      69.13\n2  Wisconsin       Dane County         344791        22.85      75.46\n3  Wisconsin       Rock County          85360        43.51      54.66\n4  Wisconsin  La Crosse County          67884        42.25      55.75\n5  Wisconsin Eau Claire County          58275        43.49      54.26\n6  Wisconsin    Portage County          40603        47.53      50.31\n  total_votes_16 dem_pct_16\n1         434970      66.44\n2         304729      71.38\n3          75043      52.42\n4          62785      51.61\n5          54080      50.43\n6          38123      48.59\n\nCode# Nothing changed.\n\n\n\n11.5.0.3 Part c\n\n11.5.0.3.0.1 So the order of filter() and arrange() did not matter – rerranging them produces the same results. BUT what is one advantage of filtering before arranging?\nBy filtering first, you reduce the dataset’s size before arranging, which can significantly improve performance, especially with large datasets. This way, you only sort the relevant data, saving time and computational resources therefore making it efficient.\n\n11.5.0.4 Part d\n\nCode elections_small |&gt; \n   filter(state_name == \"Delaware\") |&gt; \n   mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt; \n   select(county_name, repub_pct_20, dem_pct_20, repub_win_20)\n\n        county_name repub_pct_20 dem_pct_20 repub_win_20\n1       Kent County        47.12      51.19        FALSE\n2 New Castle County        30.72      67.81        FALSE\n3     Sussex County        55.07      43.82         TRUE\n\nCode# Shows the only counties in Delaware that fulfill the above conditions.\n\n\n\n11.5.0.5 Part e\n\nCode# Now try it. Change the order of mutate and select below.\n# elections_small |&gt; \n#   filter(state_name == \"Delaware\") |&gt; \n#   select(county_name, repub_pct_20, dem_pct_20, repub_win_20)\n#   mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt; \n# Shows an error message because a variable cannot be selected (repub_win_20) when it hasn't been defined yet",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-6",
    "href": "ica/ica-wrangling.html#exercise-6",
    "title": "\n11  Wrangling\n",
    "section": "\n11.6 Exercise 6",
    "text": "11.6 Exercise 6\n\n11.6.0.1 Part a\n\nCode# Show just the counties in Minnesota and their Democratic 2020 vote percentage, from highest to lowest. Your answer should have just 2 columns.\n\nelections_small|&gt;\n  filter(state_name == \"Minnesota\") |&gt;\n  arrange(desc(dem_pct_20)) |&gt;\n  select(county_name, dem_pct_20)\n\n                county_name dem_pct_20\n1             Ramsey County      71.50\n2           Hennepin County      70.46\n3               Cook County      65.58\n4          St. Louis County      56.64\n5             Dakota County      55.73\n6            Olmsted County      54.16\n7         Washington County      53.46\n8         Blue Earth County      50.84\n9               Clay County      50.74\n10              Lake County      50.64\n11          Nicollet County      50.31\n12           Carlton County      49.58\n13            Winona County      49.07\n14              Rice County      48.76\n15          Mahnomen County      48.26\n16             Anoka County      47.79\n17          Beltrami County      47.24\n18            Carver County      46.37\n19             Mower County      46.00\n20             Scott County      45.52\n21           Houston County      42.42\n22           Goodhue County      41.23\n23          Freeborn County      40.96\n24            Norman County      40.80\n25            Itasca County      40.61\n26       Koochiching County      38.41\n27          Watonwan County      38.20\n28           Kittson County      38.12\n29           Stevens County      37.80\n30           Stearns County      37.58\n31          Fillmore County      37.48\n32            Steele County      37.47\n33         Kandiyohi County      36.12\n34            Aitkin County      35.98\n35              Lyon County      35.94\n36     Lac qui Parle County      35.79\n37           Wabasha County      35.78\n38             Grant County      35.58\n39          Traverse County      35.46\n40         Big Stone County      35.41\n41        Pennington County      35.29\n42              Pope County      35.27\n43              Polk County      34.88\n44              Cass County      34.68\n45            Wright County      34.49\n46           Hubbard County      34.42\n47             Swift County      34.35\n48         Crow Wing County      34.17\n49           Chisago County      34.15\n50            Becker County      33.96\n51              Pine County      33.87\n52          Le Sueur County      33.73\n53          Chippewa County      33.67\n54            Nobles County      33.65\n55            Waseca County      33.65\n56             Dodge County      33.47\n57        Otter Tail County      32.85\n58            Benton County      32.70\n59           Douglas County      32.56\n60             Brown County      32.48\n61         Sherburne County      32.48\n62         Faribault County      31.98\n63          Red Lake County      31.47\n64          Renville County      30.71\n65            McLeod County      30.64\n66   Yellow Medicine County      30.54\n67           Lincoln County      30.08\n68        Cottonwood County      30.03\n69           Kanabec County      30.02\n70            Martin County      30.02\n71           Jackson County      29.99\n72        Mille Lacs County      29.98\n73            Wilkin County      29.91\n74              Rock County      29.69\n75            Murray County      29.60\n76            Isanti County      29.45\n77            Sibley County      28.60\n78            Meeker County      28.58\n79           Redwood County      28.43\n80 Lake of the Woods County      27.87\n81        Clearwater County      26.76\n82         Pipestone County      26.44\n83            Wadena County      26.35\n84            Roseau County      25.98\n85          Marshall County      25.33\n86              Todd County      24.79\n87          Morrison County      22.33\n\n\n\n11.6.0.2 Part b\nCreate a new dataset named mn_wi that sorts the counties in Minnesota and Wisconsin from lowest to highest in terms of the change in Democratic vote percentage in 2020 vs 2016. This dataset should include the following variables (and only these variables): state_name, county_name, dem_pct_20, dem_pct_16, and a variable measuring the change in Democratic vote percentage in 2020 vs 2016.\n\nCode mn_wi &lt;- elections_small|&gt; \n  filter(state_name %in% c(\"Minnesota\", \"Wisconsin\")) |&gt;\n  mutate(dem_change = dem_pct_20 - dem_pct_16) |&gt;\n  arrange(dem_change) |&gt;\n  select(state_name, county_name, dem_pct_16, dem_pct_20, dem_change)\n\nhead(mn_wi)\n\n  state_name        county_name dem_pct_16 dem_pct_20 dem_change\n1  Minnesota     Stevens County      39.55      37.80      -1.75\n2  Wisconsin      Forest County      35.12      34.06      -1.06\n3  Wisconsin    Kewaunee County      33.73      32.87      -0.86\n4  Wisconsin       Clark County      31.19      30.37      -0.82\n5  Wisconsin       Adams County      37.40      36.63      -0.77\n6  Wisconsin Trempealeau County      41.57      40.86      -0.71\n\n\n\n11.6.0.3 Part c\nConstruct and discuss a plot of the county-level change in Democratic vote percent in 2020 vs 2016, and how this differs between Minnesota and Wisconsin.\n\nCodelibrary(tidyverse)\n\nggplot(mn_wi, aes(x = dem_change, fill = state_name)) +\n  geom_density(alpha = 0.7)\n\n\n\n\n\n\nCodeggplot(mn_wi, aes(y = dem_change, x = state_name)) +\n  geom_boxplot(alpha = 0.7)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-7",
    "href": "ica/ica-wrangling.html#exercise-7",
    "title": "\n11  Wrangling\n",
    "section": "\n11.7 Exercise 7",
    "text": "11.7 Exercise 7\n\nCode# What does this do?\n elections_small |&gt; \n   summarize(median(repub_pct_20))\n\n  median(repub_pct_20)\n1                68.29\n\nCode# Gives the middle republican percentage.\n\n\n\nCode# What does this do?\n elections_small |&gt; \n   summarize(median_repub = median(repub_pct_20))\n\n  median_repub\n1        68.29\n\nCode# Calculate the median Repub vote percentage in 2020 across all counties AND name it \"median_repub\"\n\n\n\nCode# What does this do?\nelections_small |&gt; \n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20))\n\n  median_repub total_votes\n1        68.29   157949293\n\nCode# Calculate the median Repub vote percentage in 2020 across all counties, and the total number of votes across all counties, and name the results",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-8",
    "href": "ica/ica-wrangling.html#exercise-8",
    "title": "\n11  Wrangling\n",
    "section": "\n11.8 Exercise 8",
    "text": "11.8 Exercise 8\n\nCode elections_small |&gt; \n   group_by(state_name)\n\n# A tibble: 3,109 × 7\n# Groups:   state_name [50]\n   state_name county_name  total_votes_20 repub_pct_20 dem_pct_20 total_votes_16\n   &lt;chr&gt;      &lt;chr&gt;                 &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;int&gt;\n 1 Alabama    Autauga Cou…          27770         71.4      27.0           24661\n 2 Alabama    Baldwin Cou…         109679         76.2      22.4           94090\n 3 Alabama    Barbour Cou…          10518         53.4      45.8           10390\n 4 Alabama    Bibb County            9595         78.4      20.7            8748\n 5 Alabama    Blount Coun…          27588         89.6       9.57          25384\n 6 Alabama    Bullock Cou…           4613         24.8      74.7            4701\n 7 Alabama    Butler Coun…           9488         57.5      41.8            8685\n 8 Alabama    Calhoun Cou…          50983         68.8      29.8           47376\n 9 Alabama    Chambers Co…          15284         57.3      41.6           13778\n10 Alabama    Cherokee Co…          12301         86.0      13.2           10503\n# ℹ 3,099 more rows\n# ℹ 1 more variable: dem_pct_16 &lt;dbl&gt;\n\nCode# Does nothing\n\n\n\nCode# Check out the structure before and after group_by\n elections_small |&gt; \n   class()\n\n[1] \"data.frame\"\n\nCode elections_small |&gt; \n   group_by(state_name) |&gt; \n   class()\n\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nCode# [1] \"data.frame\"\n# [1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nCode# What does this do?\n# (What if we didn't use group_by?)\n elections_small |&gt; \n   group_by(state_name) |&gt; \n   summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20)) \n\n# A tibble: 50 × 3\n   state_name           median_repub total_votes\n   &lt;chr&gt;                       &lt;dbl&gt;       &lt;int&gt;\n 1 Alabama                      70.6     2323304\n 2 Arizona                      57.9     3387326\n 3 Arkansas                     72.1     1219069\n 4 California                   44.8    17495906\n 5 Colorado                     56.2     3256953\n 6 Connecticut                  41.0     1824280\n 7 Delaware                     47.1      504010\n 8 District of Columbia          5.4      344356\n 9 Florida                      64.6    11067456\n10 Georgia                      68       4997716\n# ℹ 40 more rows",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-9",
    "href": "ica/ica-wrangling.html#exercise-9",
    "title": "\n11  Wrangling\n",
    "section": "\n11.9 Exercise 9",
    "text": "11.9 Exercise 9\n\n11.9.0.1 Part a\n\nCode# Sort the *states* from the most to least total votes cast in 2020\nelections_small |&gt; \n  group_by(state_name) |&gt; \n  summarize(total = sum(total_votes_20)) |&gt; \n  arrange(desc(total))\n\n# A tibble: 50 × 2\n   state_name        total\n   &lt;chr&gt;             &lt;int&gt;\n 1 California     17495906\n 2 Texas          11317911\n 3 Florida        11067456\n 4 New York        8616205\n 5 Pennsylvania    6925255\n 6 Illinois        6038850\n 7 Ohio            5922202\n 8 Michigan        5539302\n 9 North Carolina  5524801\n10 Georgia         4997716\n# ℹ 40 more rows\n\n\n\nCode# In 2020, what were the total number of votes for the Democratic candidate and the total number of votes for the Republican candidate in each *state*?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20))\n\n# A tibble: 50 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Alabama                 849664     1441155\n 2 Arizona                1672127     1661671\n 3 Arkansas                423919      760641\n 4 California            11109642     6006031\n 5 Colorado               1804393     1364627\n 6 Connecticut            1080677      715315\n 7 Delaware                296274      200601\n 8 District of Columbia    317324       18595\n 9 Florida                5297131     5668600\n10 Georgia                2473661     2461869\n# ℹ 40 more rows\n\n\n\nCode# What states did the Democratic candidate win in 2020?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20)) |&gt; \n  filter(dem_total &gt; repub_total)\n\n# A tibble: 26 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Arizona                1672127     1661671\n 2 California            11109642     6006031\n 3 Colorado               1804393     1364627\n 4 Connecticut            1080677      715315\n 5 Delaware                296274      200601\n 6 District of Columbia    317324       18595\n 7 Georgia                2473661     2461869\n 8 Hawaii                  366121      196865\n 9 Illinois               3471916     2446931\n10 Maine                   430466      359897\n# ℹ 16 more rows",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercise-10",
    "href": "ica/ica-wrangling.html#exercise-10",
    "title": "\n11  Wrangling\n",
    "section": "\n11.10 Exercise 10",
    "text": "11.10 Exercise 10\n\nCodeworld_cup &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-29/worldcups.csv\")\n# View(world_cup)\n\n\n\nCode# In what years did Brazil win the World Cup?\n world_cup |&gt;\n  filter(winner == \"Brazil\")\n\n  year               host winner         second        third       fourth\n1 1958             Sweden Brazil         Sweden       France West Germany\n2 1962              Chile Brazil Czechoslovakia        Chile   Yugoslavia\n3 1970             Mexico Brazil          Italy West Germany      Uruguay\n4 1994                USA Brazil          Italy       Sweden     Bulgaria\n5 2002 Japan, South Korea Brazil        Germany       Turkey  South Korea\n  goals_scored teams games attendance\n1          126    16    35     868000\n2           89    16    32     776000\n3           95    16    32    1673975\n4          141    24    52    3568567\n5          161    32    64    2724604\n\n\n\nCode# What were the 6 World Cups with the highest attendance?\n world_cup |&gt;\n  arrange(desc(attendance)) |&gt;\n  head()\n\n  year               host  winner    second       third      fourth\n1 1994                USA  Brazil     Italy      Sweden    Bulgaria\n2 2014             Brazil Germany Argentina Netherlands      Brazil\n3 2006            Germany   Italy    France     Germany    Portugal\n4 2018             Russia  France   Croatia     Belgium     England\n5 1998             France  France    Brazil     Croatia Netherlands\n6 2002 Japan, South Korea  Brazil   Germany      Turkey South Korea\n  goals_scored teams games attendance\n1          141    24    52    3568567\n2          171    32    64    3441450\n3          147    32    64    3367000\n4          169    32    64    3031768\n5          171    32    64    2859234\n6          161    32    64    2724604\n\n\n\nCode# Construct a univariate plot of goals_scored (no wrangling necessary)\n# This provides a visual summary of how the number of goals_scored varies from World Cup to World Cup\n ggplot(world_cup, aes(x=goals_scored)) +\n  geom_histogram(color = \"pink\")\n\n\n\n\n\n\n\n\nCode# Let's follow up the plot with some more precise numerical summaries\n# Calculate the min, median, and max number of goals_scored across all World Cups\n# NOTE: Visually compare these numerical summaries to what you observed in the plot\n\nworld_cup |&gt; \n  summarize(min(goals_scored), median(goals_scored), max(goals_scored))\n\n  min(goals_scored) median(goals_scored) max(goals_scored)\n1                70                  126               171\n\n\n\nCode# Construct a bivariate plot of how the number of goals_scored in the World Cup has changed over the years\n# No wrangling necessary\nggplot(world_cup, aes(x = year, y = goals_scored)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"purple\")\n\n\n\n\n\n\n\n\nCode# Our above summaries might be a bit misleading.\n# The number of games played at the World Cup varies.\n# Construct a bivariate plot of how the typical number of goals per game has changed over the years\ngoals_per_game &lt;- world_cup |&gt; \n  mutate(goals_per_game = goals_scored / games)\n\nggplot(goals_per_game, aes(x = year, y = goals_per_game)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"purple\")",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html",
    "href": "ica/ica-dates.html",
    "title": "\n12  Dates\n",
    "section": "",
    "text": "12.1 Exercises Part 1",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html#exercises-part-1",
    "href": "ica/ica-dates.html#exercises-part-1",
    "title": "\n12  Dates\n",
    "section": "",
    "text": "12.1.0.1 Exercise 1\n\n12.1.0.1.0.1 Part a\n\nCode# Create a dataset with just Adelie and Chinstrap using %in%\n# Pipe this into `count(species)` to confirm that you only have these 2 species\n penguins |&gt; \n   filter(species %in% c(\"Adelie\", \"Chinstrap\")) |&gt; \n   count(species)\n\n# A tibble: 2 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n\n\n\nCode# Create a dataset with just Adelie and Chinstrap using !=\n# Pipe this into `count(species)` to confirm that you only have these 2 species\n penguins |&gt; \n   filter(species != c(\"Gentoo\")) |&gt; \n   count(species)\n\n# A tibble: 2 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n\n\n\n12.1.0.1.0.2 Part b\n\nCodehead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\nExample 1\n\nCode# NOTE the use of is.na()\npenguins |&gt; \n  summarize(sum(is.na(body_mass_g)))\n\n# A tibble: 1 × 1\n  `sum(is.na(body_mass_g))`\n                      &lt;int&gt;\n1                         2\n\n\n\nCode# NOTE the use of is.na()\npenguins_w_body_mass &lt;- penguins |&gt; \n  filter(!is.na(body_mass_g))\n\n# Compare the number of penguins in this vs the original data\nnrow(penguins_w_body_mass)\n\n[1] 342\n\n\n\nCodenrow(penguins)\n\n[1] 344\n\n\n\nCodepenguins_w_body_mass |&gt; \n  summarize(sum(is.na(sex)))\n\n# A tibble: 1 × 1\n  `sum(is.na(sex))`\n              &lt;int&gt;\n1                 9\n\n\nExample 2\n\nCodepenguins_complete &lt;- penguins |&gt; \n  na.omit()\n\n\n\nCodenrow(penguins_complete)\n\n[1] 333\n\n\n\nCodenrow(penguins)\n\n[1] 344\n\n\n\n12.1.0.1.0.3 Part c\nExplain why we should only use na.omit() in extreme circumstances. …..\n\n12.1.0.2 Exercise 2\n\nCode# First: recall the variable names\nnames(penguins)\n\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\n\n\nCode# Use a shortcut to keep everything but the year and island variables\npenguins |&gt;\n  select (-year, -island)\n\n# A tibble: 344 × 6\n   species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt; \n 1 Adelie            39.1          18.7               181        3750 male  \n 2 Adelie            39.5          17.4               186        3800 female\n 3 Adelie            40.3          18                 195        3250 female\n 4 Adelie            NA            NA                  NA          NA &lt;NA&gt;  \n 5 Adelie            36.7          19.3               193        3450 female\n 6 Adelie            39.3          20.6               190        3650 male  \n 7 Adelie            38.9          17.8               181        3625 female\n 8 Adelie            39.2          19.6               195        4675 male  \n 9 Adelie            34.1          18.1               193        3475 &lt;NA&gt;  \n10 Adelie            42            20.2               190        4250 &lt;NA&gt;  \n# ℹ 334 more rows\n\n\n\nCode# Use a shortcut to keep only species and the penguin characteristics measured in mm\npenguins |&gt; \n  select(species, ends_with(\"mm\"))\n\n# A tibble: 344 × 4\n   species bill_length_mm bill_depth_mm flipper_length_mm\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n 1 Adelie            39.1          18.7               181\n 2 Adelie            39.5          17.4               186\n 3 Adelie            40.3          18                 195\n 4 Adelie            NA            NA                  NA\n 5 Adelie            36.7          19.3               193\n 6 Adelie            39.3          20.6               190\n 7 Adelie            38.9          17.8               181\n 8 Adelie            39.2          19.6               195\n 9 Adelie            34.1          18.1               193\n10 Adelie            42            20.2               190\n# ℹ 334 more rows\n\n\n\nCode# Use a shortcut to keep only species and bill-related measurements\npenguins |&gt; \n  select(species, starts_with(\"bill\"))\n\n# A tibble: 344 × 3\n   species bill_length_mm bill_depth_mm\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 Adelie            39.1          18.7\n 2 Adelie            39.5          17.4\n 3 Adelie            40.3          18  \n 4 Adelie            NA            NA  \n 5 Adelie            36.7          19.3\n 6 Adelie            39.3          20.6\n 7 Adelie            38.9          17.8\n 8 Adelie            39.2          19.6\n 9 Adelie            34.1          18.1\n10 Adelie            42            20.2\n# ℹ 334 more rows\n\n\n\nCode# Use a shortcut to keep only species and the length-related characteristics\npenguins |&gt; \n  select(species, contains(\"length\"))\n\n# A tibble: 344 × 3\n   species bill_length_mm flipper_length_mm\n   &lt;chr&gt;            &lt;dbl&gt;             &lt;dbl&gt;\n 1 Adelie            39.1               181\n 2 Adelie            39.5               186\n 3 Adelie            40.3               195\n 4 Adelie            NA                  NA\n 5 Adelie            36.7               193\n 6 Adelie            39.3               190\n 7 Adelie            38.9               181\n 8 Adelie            39.2               195\n 9 Adelie            34.1               193\n10 Adelie            42                 190\n# ℹ 334 more rows\n\n\n\n12.1.0.3 Exercise 3\n\nCode# Change this code to sort the penguins by species, and then island name\n# NOTE: The first row should be an Adelie penguin living on Biscoe island\npenguins |&gt; \n  arrange(species, island)\n\n# A tibble: 344 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Adelie  Biscoe           37.8          18.3               174        3400\n 2 Adelie  Biscoe           37.7          18.7               180        3600\n 3 Adelie  Biscoe           35.9          19.2               189        3800\n 4 Adelie  Biscoe           38.2          18.1               185        3950\n 5 Adelie  Biscoe           38.8          17.2               180        3800\n 6 Adelie  Biscoe           35.3          18.9               187        3800\n 7 Adelie  Biscoe           40.6          18.6               183        3550\n 8 Adelie  Biscoe           40.5          17.9               187        3200\n 9 Adelie  Biscoe           37.9          18.6               172        3150\n10 Adelie  Biscoe           40.5          18.9               180        3950\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\nCode# Change this code to count the number of male/female penguins observed for each species\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\n\nCode# Change this code to calculate the average body mass by species and sex\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(mean = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex     mean\n  &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie    female 3369.\n2 Adelie    male   4043.\n3 Adelie    &lt;NA&gt;   3540 \n4 Chinstrap female 3527.\n5 Chinstrap male   3939.\n6 Gentoo    female 4680.\n7 Gentoo    male   5485.\n8 Gentoo    &lt;NA&gt;   4588.\n\n\n\n12.1.0.4 Exercise 4\n\nCode# Get today's date\nas.Date(today())\n\n[1] \"2025-04-21\"\n\n\n\nCode# Let's store this as \"today\" so we can work with it below\ntoday &lt;- as.Date(today())\n\n# Check out the class of this object\nclass(today)\n\n[1] \"Date\"\n\n\n\nCodeyear(today)\n\n[1] 2025\n\n\n\nCode# What do these lines produce / what's their difference?\nmonth(today)\n\n[1] 4\n\n\n\nCodemonth(today, label = TRUE)\n\n[1] Apr\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n\n\nCode# What does this number mean?\nweek(today)\n\n[1] 16\n\n\n\nCode# What do these lines produce / what's their difference?\nmday(today)\n\n[1] 21\n\n\n\nCodeyday(today)  # This is often called the \"Julian day\"\n\n[1] 111\n\n\n\nCode# What do these lines produce / what's their difference?\nwday(today)\n\n[1] 2\n\n\n\nCodewday(today, label = TRUE)\n\n[1] Mon\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\n\nCode# What do the results of these 2 lines tell us?\ntoday &gt;= ymd(\"2024-02-14\")\n\n[1] TRUE\n\n\n\nCodetoday &lt; ymd(\"2024-02-14\")\n\n[1] FALSE",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html#exercises-part-2",
    "href": "ica/ica-dates.html#exercises-part-2",
    "title": "\n12  Dates\n",
    "section": "\n12.2 Exercises Part 2",
    "text": "12.2 Exercises Part 2\n\nCodelibrary(mosaic)\ndata(\"Birthdays\")\nhead(Birthdays)\n\n  state year month day       date wday births\n1    AK 1969     1   1 1969-01-01  Wed     14\n2    AL 1969     1   1 1969-01-01  Wed    174\n3    AR 1969     1   1 1969-01-01  Wed     78\n4    AZ 1969     1   1 1969-01-01  Wed     84\n5    CA 1969     1   1 1969-01-01  Wed    824\n6    CO 1969     1   1 1969-01-01  Wed    100\n\nCodedim(Birthdays)\n\n[1] 372864      7\n\n\n\n12.2.0.1 Exercise 5\n\nCode# How many days of data do we have for each state?\nbirthdays_days_per_state &lt;- Birthdays |&gt;\n  group_by(state) |&gt;\n  summarise(days_of_data = n_distinct(date))\nprint(birthdays_days_per_state)\n\n# A tibble: 51 × 2\n   state days_of_data\n   &lt;chr&gt;        &lt;int&gt;\n 1 AK            7305\n 2 AL            7305\n 3 AR            7305\n 4 AZ            7305\n 5 CA            7305\n 6 CO            7305\n 7 CT            7305\n 8 DC            7305\n 9 DE            7305\n10 FL            7305\n# ℹ 41 more rows\n\nCode# How many total births were there in this time period?\ntotal_births &lt;- sum(Birthdays$births)\nprint(total_births)\n\n[1] 70486538\n\nCode# How many total births were there per state in this time period, sorted from low to high?\nbirths_per_state &lt;- Birthdays |&gt;\n  group_by(state) |&gt;\n  summarise(total_births = sum(births)) |&gt;\n  arrange(total_births)\nprint(births_per_state)\n\n# A tibble: 51 × 2\n   state total_births\n   &lt;chr&gt;        &lt;int&gt;\n 1 VT          147886\n 2 WY          154019\n 3 AK          185385\n 4 DE          188705\n 5 SD          235734\n 6 ND          238696\n 7 NV          241470\n 8 MT          253884\n 9 NH          264984\n10 RI          265038\n# ℹ 41 more rows\n\n\n\n12.2.0.2 Exercise 6\nCreate a new dataset named daily_births that includes the total number of births per day (across all states) and the corresponding day of the week, eg, Mon. NOTE: Name the column with total births so that it’s easier to wrangle and plot.\nUsing this data, construct a plot of births over time, indicating the day of week.\n\nCodedaily_births &lt;- Birthdays |&gt;\n  group_by(date) |&gt;\n  summarise(total_births = sum(births)) |&gt;\n  mutate(day_of_week = weekdays(date)) |&gt;\n  mutate(day_of_week = fct_relevel(day_of_week, c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")))\n\nhead(daily_births)\n\n# A tibble: 6 × 3\n  date                total_births day_of_week\n  &lt;dttm&gt;                     &lt;int&gt; &lt;fct&gt;      \n1 1969-01-01 00:00:00         8486 Wednesday  \n2 1969-01-02 00:00:00         9002 Thursday   \n3 1969-01-03 00:00:00         9542 Friday     \n4 1969-01-04 00:00:00         8960 Saturday   \n5 1969-01-05 00:00:00         8390 Sunday     \n6 1969-01-06 00:00:00         9560 Monday     \n\nCodeggplot(daily_births, aes(x = date, y = total_births, color = day_of_week)) +\n  geom_line() +\n  labs(title = \"Total Births Over Time by Day of the Week\",\n       x = \"Date\",\n       y = \"Total Births\",\n       color = \"Day of Week\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\n12.2.0.3 Exercise 7\n\n12.2.0.3.0.1 Part a\nCalculate the total number of births in each month and year, eg, Jan 1969, Feb 1969, …. Label month by names not numbers, eg, Jan not 1. Then, plot the births by month and comment on what you learn.\n\nCode# Either this one \nmonthly_births &lt;- Birthdays |&gt;\n  mutate(month_name = month.abb[month]) |&gt;  \n  group_by(year, month_name) |&gt;\n  summarize(total_births = sum(births), .groups = \"drop\") |&gt;\n  mutate(month_name = factor(month_name, levels = month.abb))\n  \n  #View(monthly_births)\n\nggplot(monthly_births, aes(x = month_name, y = total_births)) +\n  geom_boxplot(fill = \"steelblue\", color = \"black\", alpha = 0.5) +\n  labs(\n    title = \"Total Births by Month (Across All Years)\",\n    x = \"Month\",\n    y = \"Total Births\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nCode# OR this onr, not sure\nbirths_by_month_year &lt;- Birthdays |&gt;\n  mutate(month = format(date, \"%b\"),       \n         year = format(date, \"%Y\")) |&gt;     \n  group_by(month, year) |&gt;                 \n  summarise(total_births = sum(births)) |&gt;  \n  arrange(year, match(month, month.name))  \n\nhead(births_by_month_year)\n\n# A tibble: 6 × 3\n# Groups:   month [6]\n  month year  total_births\n  &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;\n1 May   1969        289070\n2 Apr   1969        282470\n3 Aug   1969        320922\n4 Dec   1969        314540\n5 Feb   1969        270534\n6 Jan   1969        293876\n\nCodeggplot(births_by_month_year, aes(x = interaction(month, year), y = total_births, group = year)) +\n  geom_line(aes(color = year)) + \n  labs(title = \"Total Births by Month and Year\",\n       x = \"Month-Year\",\n       y = \"Total Births\",\n       color = \"Year\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n12.2.0.3.0.2 Part b\nIn 1988, calculate the total number of births per week in each state. Get rid of week “53”, which isn’t a complete week! Then, make a line plot of births by week for each state and comment on what you learn. For example, do you notice any seasonal trends? Are these the same in every state? Any outliers?\n\nCodebirths_per_week_1988 &lt;- Birthdays |&gt;\n  filter(format(date, \"%Y\") == \"1988\") |&gt;   \n  mutate(week = format(date, \"%U\")) |&gt;        \n  filter(week != \"53\") |&gt;                     \n  group_by(state, week) |&gt;                    \n  summarise(total_births = sum(births), .groups = 'drop')  \n\n  ggplot(births_per_week_1988, aes(x = as.integer(week), y = total_births, color = state, group = state)) +\n  geom_line() + \n  labs(title = \"Total Births by Week in 1988 (by State)\",\n       x = \"Week of Year\",\n       y = \"Total Births\",\n       color = \"State\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\n12.2.0.3.0.3 Part c\nRepeat the above for just Minnesota (MN) and Louisiana (LA). MN has one of the coldest climates and LA has one of the warmest. How do their seasonal trends compare? Do you think these trends are similar in other colder and warmer states? Try it!\n\nCodemn_la_births &lt;- Birthdays |&gt; \n  filter(year == 1988) |&gt; \n  filter(state %in% c(\"MN\", \"LA\")) |&gt; \n  mutate(week_start = floor_date(date, unit = \"week\")) |&gt; \n  group_by(state, week_start) |&gt;\n  summarize(total_births = sum(births), .groups = \"drop\") \n  \n  if (nrow(mn_la_births) == 0) {\n  stop(\"No data found for Minnesota (MN) or Louisiana (LA). Check the dataset.\")\n}\n\nggplot(mn_la_births, aes(x = week_start, y = total_births, color = state)) +\n  geom_smooth(size = 1, method = \"lm\") +\n  labs(\n    title = \"Weekly Birth Trends in Minnesota and Louisiana (1988)\",\n    x = \"Week Start Date\",\n    y = \"Total Births\",\n    color = \"State\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14, hjust = 0.5),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n12.2.0.4 Exercise 8\n\n12.2.0.4.0.1 Part a\nCreate a dataset with only births in Massachusetts (MA) in 1979 and sort the days from those with the most births to those with the fewest.\n\nCodema_births_1979 &lt;- Birthdays |&gt;\n  filter(state == \"MA\" & format(date, \"%Y\") == \"1979\") |&gt;  \n  group_by(date) |&gt;  # Group by date\n  summarise(total_births = sum(births), .groups = 'drop') |&gt;  \n  arrange(desc(total_births))  \n\nhead(ma_births_1979)\n\n# A tibble: 6 × 2\n  date                total_births\n  &lt;dttm&gt;                     &lt;int&gt;\n1 1979-09-28 00:00:00          262\n2 1979-09-11 00:00:00          252\n3 1979-12-28 00:00:00          249\n4 1979-09-26 00:00:00          246\n5 1979-07-24 00:00:00          245\n6 1979-04-27 00:00:00          243\n\n\n\n12.2.0.5 Part b\nMake a table showing the five states with the most births between September 9, 1979 and September 12, 1979, including the 9th and 12th. Arrange the table in descending order of births.\n\nCodebirths_sept_9_12_1979 &lt;- Birthdays |&gt;\n  filter(date &gt;= \"1979-09-09\" & date &lt;= \"1979-09-12\") |&gt; \n  group_by(state) |&gt;                                        \n  summarise(total_births = sum(births), .groups = 'drop') |&gt; \n  arrange(desc(total_births))  \n\ntop_5_states &lt;- head(births_sept_9_12_1979, 5)\n\ntop_5_states\n\n# A tibble: 5 × 2\n  state total_births\n  &lt;chr&gt;        &lt;int&gt;\n1 CA            3454\n2 TX            2467\n3 NY            2036\n4 IL            1758\n5 OH            1527",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html",
    "href": "ica/ica-reshaping.html",
    "title": "\n13  Reshaping\n",
    "section": "",
    "text": "13.1 Exercise 1\nCodesleep_wide &lt;- read.csv(\"https://mac-stat.github.io/data/sleep_wide.csv\")\n\nhead(sleep_wide)\n\n  Subject  day_0  day_1  day_2  day_3  day_4  day_5  day_6  day_7  day_8  day_9\n1     308 249.56 258.70 250.80 321.44 356.85 414.69 382.20 290.15 430.59 466.35\n2     309 222.73 205.27 202.98 204.71 207.72 215.96 213.63 217.73 224.30 237.31\n3     310 199.05 194.33 234.32 232.84 229.31 220.46 235.42 255.75 261.01 247.52\n4     330 321.54 300.40 283.86 285.13 285.80 297.59 280.24 318.26 305.35 354.05\n5     331 287.61 285.00 301.82 320.12 316.28 293.32 290.08 334.82 293.75 371.58\n6     332 234.86 242.81 272.96 309.77 317.46 310.00 454.16 346.83 330.30 253.86",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#exercise-1",
    "href": "ica/ica-reshaping.html#exercise-1",
    "title": "\n13  Reshaping\n",
    "section": "",
    "text": "13.1.0.1 Part a",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#what-are-the-units-of-observation-in-sleep_wide",
    "href": "ica/ica-reshaping.html#what-are-the-units-of-observation-in-sleep_wide",
    "title": "\n13  Reshaping\n",
    "section": "\n13.2 What are the units of observation in sleep_wide?",
    "text": "13.2 What are the units of observation in sleep_wide?\n\n13.2.0.1 Part b\nSuppose I ask you to plot each subject’s reaction time (y-axis) vs the number of days of sleep restriction (x-axis). “Sketch” out in words what the first few rows of the data need to look like in order to do this. It might help to think about what you’d need to complete the plotting frame:\n\nThe first few rows need to have days on their own, reaction time and the subject is.\n\n13.2.0.2 Part c\n\nCode# How can you obtain the dataset you sketched in part b?\nlibrary(tidyverse)\nlibrary(tidyr)\n\nsleep_pivot_long &lt;- sleep_wide |&gt; \n  pivot_longer(\n    cols = starts_with(\"day\"),  \n    names_to = \"day\", \n    values_to = \"reaction_time\"\n  ) |&gt; \n  mutate(day = as.numeric(gsub(\"day_\", \"\", day))) \n\nhead(sleep_pivot_long)\n\n# A tibble: 6 × 3\n  Subject   day reaction_time\n    &lt;int&gt; &lt;dbl&gt;         &lt;dbl&gt;\n1     308     0          250.\n2     308     1          259.\n3     308     2          251.\n4     308     3          321.\n5     308     4          357.\n6     308     5          415.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#exercise-2",
    "href": "ica/ica-reshaping.html#exercise-2",
    "title": "\n13  Reshaping\n",
    "section": "\n13.3 Exercise 2",
    "text": "13.3 Exercise 2\n\n13.3.0.1 Part a\n\nCode# For cols, try 2 appproaches: using - and starts_with\n# ___ |&gt; \n#   pivot_longer(cols = ___, names_to = \"___\", values_to = \"___\")\n\n\n\n13.3.0.2 Part b\n\nCodesleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\")\n\nhead(sleep_long)\n\n# A tibble: 6 × 3\n  Subject day   reaction_time\n    &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n1     308 0              250.\n2     308 1              259.\n3     308 2              251.\n4     308 3              321.\n5     308 4              357.\n6     308 5              415.\n\n\n\n13.3.0.3 Part c\nUsing sleep_long, construct a line plot of reaction time vs day for each subject. This will look goofy no matter what you do. Why? HINT: look back at head(sleep_long). What class or type of variables are Subject and day? What do we want them to be?\n\nCodesleep_long |&gt; \n#  filter(subject == 308) |&gt; \n  ggplot(aes(x = day, y = reaction_time)) +  \n  geom_line(color = \"blue\", size = 2, alpha = 0.5) +\n  labs(\n    title = \"Reaction Time per Day for Subject 308\",\n    x = \"Day\",\n    y = \"Reaction Time\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#exercise-3",
    "href": "ica/ica-reshaping.html#exercise-3",
    "title": "\n13  Reshaping\n",
    "section": "\n13.4 Exercise 3",
    "text": "13.4 Exercise 3\n\nCodesleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") |&gt; \n  mutate(Subject = as.factor(Subject), day = as.numeric(day))\n\n# Check it out\n# Same data, different class\nhead(sleep_long)\n\n# A tibble: 6 × 3\n  Subject   day reaction_time\n  &lt;fct&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n1 308         0          250.\n2 308         1          259.\n3 308         2          251.\n4 308         3          321.\n5 308         4          357.\n6 308         5          415.\n\n\n\n13.4.0.1 Part a\n\nCode# Make a line plot of reaction time by day for each subject\n# Put these all on the same frame\n\nggplot(sleep_long, aes(x = day, y = reaction_time, color = Subject)) +\n  geom_line(color = \"blue\")\n\n\n\n\n\n\n\n\nCode# Make a line plot of reaction time by day for each subject\n# Put these all on separate frames (one per subject)\n\nggplot(sleep_long, aes(x = day, y = reaction_time, group = Subject)) + \n  geom_line(color = \"blue\") +\n  facet_wrap(~Subject)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#exercise-4",
    "href": "ica/ica-reshaping.html#exercise-4",
    "title": "\n13  Reshaping\n",
    "section": "\n13.5 Exercise 4",
    "text": "13.5 Exercise 4\n\n13.5.0.1 Part a\nMake the data wide again, with each day becoming its own column.\n\nCode sleep_long |&gt;\n   pivot_wider(names_from = day, values_from = reaction_time) |&gt; \n   head()\n\n# A tibble: 6 × 11\n  Subject   `0`   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\n\n13.5.0.2 Part b\nUsing your intuition, adjust your code from part a to name the reaction time columns “day_0”, “day_1”, etc.\n\nCodesleep_long |&gt;\n   pivot_wider(names_from = day, values_from = reaction_time, names_prefix = \"day_\") |&gt; \n   head()\n\n# A tibble: 6 × 11\n  Subject day_0 day_1 day_2 day_3 day_4 day_5 day_6 day_7 day_8 day_9\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#exercise-5",
    "href": "ica/ica-reshaping.html#exercise-5",
    "title": "\n13  Reshaping\n",
    "section": "\n13.6 Exercise 5",
    "text": "13.6 Exercise 5\n\nCode# Load data\nlibrary(tidyr)\ndata(\"billboard\")\n\n# Check it out\nhead(billboard)\n\n# A tibble: 6 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n6 98^0        Give… 2000-08-19      51    39    34    26    26    19     2     2\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n\n\n13.6.0.1 Part a\nConstruct and summarize a plot of how a song’s Billboard ranking its 2nd week on the chart (y-axis) is related to its ranking the 1st week on the charts (x-axis). Add a reference line geom_abline(intercept = 0, slope = 1). Songs above this line improved their rankings from the 1st to 2nd week.\n\nCodebillboard_long &lt;- billboard |&gt;\n  pivot_longer(cols = starts_with(\"wk\"), names_to = \"week\", values_to = \"rank\", values_drop_na = TRUE) |&gt;\n  mutate(week = as.numeric(gsub(\"wk\", \"\", week)))  \n\nbillboard_weeks &lt;- billboard_long |&gt;\n  filter(week %in% c(1, 2)) |&gt;\n  pivot_wider(names_from = week, values_from = rank, names_prefix = \"week_\")\n\nggplot(billboard_weeks, aes(x = week_1, y = week_2)) +\n  geom_point(color = \"blue\", alpha = 0.5) +  \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Billboard Rankings: Week 1 vs Week 2\",\n    x = \"Ranking in 1st Week\",\n    y = \"Ranking in 2nd Week\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n13.6.0.2 Part b\nUse your wrangling tools to identify which songs are those above the line in Part a, i.e. with rankgings that went up from week 1 to week 2.\n\nCodesongs_improved &lt;- billboard_weeks |&gt;\n  filter(week_2 &lt; week_1) |&gt;\n  select(artist, track, week_1, week_2) |&gt;\n  arrange(week_2)  \n\nprint(songs_improved)\n\n# A tibble: 255 × 4\n   artist                           track             week_1 week_2\n   &lt;chr&gt;                            &lt;chr&gt;              &lt;dbl&gt;  &lt;dbl&gt;\n 1 \"Santana\"                        Maria, Maria          15      8\n 2 \"Pink\"                           There U Go            25     15\n 3 \"N'Sync\"                         Bye Bye Bye           42     20\n 4 \"Elliott, Missy \\\"Misdemeanor\\\"\" Hot Boyz              36     21\n 5 \"Madonna\"                        Music                 41     23\n 6 \"Backstreet Boys, The\"           Shape Of My Heart     39     25\n 7 \"Martin, Ricky\"                  She Bangs             38     28\n 8 \"Dixie Chicks, The\"              Goodbye Earl          40     29\n 9 \"Eiffel 65\"                      Blue                  67     29\n10 \"Guy\"                            Dancin'               46     29\n# ℹ 245 more rows\n\n\n\n13.6.0.3 Part c\nDefine a new dataset, nov_1999, which: only includes data on songs that entered the Billboard charts on November 6, 1999 keeps all variables except track and date.entered. HINT: How can you avoid writing out all the variable names you want to keep?\n\nCodenov_1999 &lt;- billboard |&gt;\n  filter(date.entered == as.Date(\"1999-11-06\")) |&gt;\n  select(-track, -date.entered)\nprint(nov_1999)\n\n# A tibble: 2 × 77\n  artist   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  wk12\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Count…    84    70    66    60    46    37    35    35    35    32    29    29\n2 Hill,…    81    68    62    51    42    35    28    28    28    43    30    23\n# ℹ 64 more variables: wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;,\n#   wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;, wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;,\n#   wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;, wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;,\n#   wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;, wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;,\n#   wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;, wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;,\n#   wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;, wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;,\n#   wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, wk49 &lt;dbl&gt;, wk50 &lt;dbl&gt;, wk51 &lt;dbl&gt;, wk52 &lt;dbl&gt;, …\n\n\n\n13.6.0.4 Part d\nCreate and discuss a visualization of the rankings (y-axis) over time (x-axis) for the 2 songs in nov_1999. There are hints below (if you scroll), but you’re encouraged to play around and use as few hints as possible.\nHints: Should you first pivot wider or longer? Once you pivot, the week number is turned into a character variable. How can you change it to a number?\n\nCodenov_1999_long &lt;- nov_1999 |&gt; \n  pivot_longer(cols = starts_with(\"wk\"), names_to = \"week\", values_to = \"rank\", values_drop_na = TRUE) |&gt; \n  mutate(week = as.numeric(gsub(\"wk\", \"\", week)))  \n\nggplot(nov_1999_long, aes(x = week, y = rank)) +\n  geom_line(size = 1) +  \n  geom_point(size = 2) +\n  scale_y_reverse() +  \n  labs(\n    title = \"Billboard Rankings Over Time for Songs Entered on Nov 6, 1999\",\n    x = \"Week Number\",\n    y = \"Billboard Rank\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#exercise-6",
    "href": "ica/ica-reshaping.html#exercise-6",
    "title": "\n13  Reshaping\n",
    "section": "\n13.7 Exercise 6",
    "text": "13.7 Exercise 6\n\nCodelibrary(fivethirtyeight)\ndata(\"daily_show_guests\")\ndaily &lt;- daily_show_guests\nhead(daily)\n\n# A tibble: 6 × 5\n   year google_knowledge_occupation show       group  raw_guest_list  \n  &lt;int&gt; &lt;chr&gt;                       &lt;date&gt;     &lt;chr&gt;  &lt;chr&gt;           \n1  1999 actor                       1999-01-11 Acting Michael J. Fox  \n2  1999 comedian                    1999-01-12 Comedy Sandra Bernhard \n3  1999 television actress          1999-01-13 Acting Tracey Ullman   \n4  1999 film actress                1999-01-14 Acting Gillian Anderson\n5  1999 actor                       1999-01-18 Acting David Alan Grier\n6  1999 actor                       1999-01-19 Acting William Baldwin \n\n\n\n13.7.0.1 Part a\nIdentify the 15 guests that appeared the most. (This isn’t a very diverse guest list!)\n\nCodetop_15_guests &lt;- daily |&gt; \n  count(raw_guest_list, sort = TRUE) |&gt;  \n  top_n(15, n)  \n\nprint(top_15_guests)\n\n# A tibble: 16 × 2\n   raw_guest_list        n\n   &lt;chr&gt;             &lt;int&gt;\n 1 Fareed Zakaria       19\n 2 Denis Leary          17\n 3 Brian Williams       16\n 4 Paul Rudd            13\n 5 Ricky Gervais        13\n 6 Tom Brokaw           12\n 7 Bill O'Reilly        10\n 8 Reza Aslan           10\n 9 Richard Lewis        10\n10 Will Ferrell         10\n11 Sarah Vowell          9\n12 Adam Sandler          8\n13 Ben Affleck           8\n14 Louis C.K.            8\n15 Maggie Gyllenhaal     8\n16 Mike Huckabee         8\n\n\n\n13.7.0.2 Part b\nCHALLENGE: Create the following data set containing 19 columns:\nThe first column should have the 15 guests with the highest number of total appearances on the show, listed in descending order of number of appearances. 17 columns should show the number of appearances of the corresponding guest in each year from 1999 to 2015 (one per column). Another column should show the total number of appearances for the corresponding guest over the entire duration of the show.\n\nCodedaily |&gt; \n  count(year, raw_guest_list) |&gt; \n  group_by(raw_guest_list) |&gt; \n  mutate(total = sum(n)) |&gt;\n  pivot_wider(names_from = year, \n              values_from = n,\n              values_fill = 0) |&gt; \n  arrange(desc(total)) |&gt; \n  head(15)\n\n# A tibble: 15 × 19\n# Groups:   raw_guest_list [15]\n   raw_guest_list  total `1999` `2000` `2001` `2002` `2003` `2004` `2005` `2006`\n   &lt;chr&gt;           &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n 1 Fareed Zakaria     19      0      0      1      0      1      2      2      2\n 2 Denis Leary        17      1      0      1      2      1      0      0      1\n 3 Brian Williams     16      0      0      0      0      1      1      2      1\n 4 Paul Rudd          13      1      0      1      1      1      1      1      0\n 5 Ricky Gervais      13      0      0      0      0      0      0      1      2\n 6 Tom Brokaw         12      0      0      0      1      0      2      1      0\n 7 Richard Lewis      10      1      0      2      2      1      1      0      0\n 8 Will Ferrell       10      0      1      1      0      1      1      1      1\n 9 Bill O'Reilly      10      0      0      1      1      0      1      1      0\n10 Reza Aslan         10      0      0      0      0      0      0      1      2\n11 Sarah Vowell        9      0      0      0      1      0      1      1      1\n12 Adam Sandler        8      1      2      0      1      0      0      0      1\n13 Ben Affleck         8      0      0      0      0      2      0      0      1\n14 Maggie Gyllenh…     8      0      0      0      0      1      0      1      1\n15 Louis C.K.          8      0      0      0      0      0      0      0      1\n# ℹ 9 more variables: `2007` &lt;int&gt;, `2008` &lt;int&gt;, `2009` &lt;int&gt;, `2010` &lt;int&gt;,\n#   `2011` &lt;int&gt;, `2012` &lt;int&gt;, `2013` &lt;int&gt;, `2014` &lt;int&gt;, `2015` &lt;int&gt;\n\n\n\n13.7.0.3 Part c\nLet’s recreate the first figure from the article. This groups all guests into 3 broader occupational categories. However, our current data has 18 categories:\n\nCodeplot_data &lt;- daily |&gt; \n  mutate(broad_group = case_when(\n    group %in% c(\"Acting\", \"Athletics\", \"Comedy\", \"Musician\") ~ \"Acting, Comedy & Music\",\n    group %in% c(\"Media\", \"media\", \"Science\", \"Academic\", \"Consultant\", \"Clergy\") ~ \"Media\",\n    group %in% c(\"Politician\", \"Political Aide\", \"Government\", \"Military\", \"Business\", \"Advocacy\") ~ \"Government and Politics\",\n    .default = NA\n  )) |&gt; \n  filter(!is.na(broad_group))\n\n\n\nCodeplot_data |&gt;\n  group_by(year, broad_group) |&gt;\n  summarise(n = n()) |&gt;\n  mutate(freq = n / sum(n)) |&gt; \n  ggplot(aes(y = freq, x = year, color = broad_group)) + \n    geom_line()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html",
    "href": "ica/ica-joining.html",
    "title": "\n14  Joining\n",
    "section": "",
    "text": "14.1 Exercise 1",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#exercise-1",
    "href": "ica/ica-joining.html#exercise-1",
    "title": "\n14  Joining\n",
    "section": "",
    "text": "14.1.0.1 Part a\nDefine two new datasets, with different students and courses:\n\nCodelibrary(tidyverse)\nstudents_2 &lt;- data.frame(\n  student = c(\"D\", \"E\", \"F\"),\n  class = c(\"COMP 101\", \"BIOL 101\", \"POLI 101\")\n)\n\n# Check it out\nstudents_2\n\n  student    class\n1       D COMP 101\n2       E BIOL 101\n3       F POLI 101\n\n\n\nCodeenrollments_2 &lt;- data.frame(\n  course = c(\"ART 101\", \"BIOL 101\", \"COMP 101\"),\n  enrollment = c(18, 20, 19)\n)\n\n# Check it out\nenrollments_2\n\n    course enrollment\n1  ART 101         18\n2 BIOL 101         20\n3 COMP 101         19\n\n\nTo connect the course enrollments to the students’ courses, try do a left_join(). You get an error! Identify the problem by reviewing the error message and the datasets we’re trying to join.\n\nCode# eval = FALSE: don't evaluate this chunk when knitting. it produces an error.\n#students_2 |&gt; \n#  left_join(enrollments_2)\n\n\n\nCode#students_2 |&gt; \n#  cross_join(enrollments_2)\n# error from chunk above was Use \"`cross_join()` to perform a cross-join.\"\n\n\n\n14.1.0.2 Part b\nThe problem is that course name, the key or variable that links these two datasets, is labeled differently: class in the students_2 data and course in the enrollments_2 data. Thus we have to specify these keys in our code:\n\nCodestudents_2 |&gt; \n  left_join(enrollments_2, join_by(class == course))\n\n  student    class enrollment\n1       D COMP 101         19\n2       E BIOL 101         20\n3       F POLI 101         NA\n\n\n\nCode# The order of the keys is important:\n# join_by(\"left data key\" == \"right data key\")\n# The order is mixed up here, thus we get an error:\n#students_2 |&gt; \n#  left_join(enrollments_2, join_by(course == class))\n# Error message is \"Problem with `course`.\"\n\n\n\n14.1.0.3 Part c\nDefine another set of fake data which adds grade information:\n\nCode# Add student grades in each course\nstudents_3 &lt;- data.frame(\n  student = c(\"Y\", \"Y\", \"Z\", \"Z\"),\n  class = c(\"COMP 101\", \"BIOL 101\", \"POLI 101\", \"COMP 101\"),\n  grade = c(\"B\", \"S\", \"C\", \"A\")\n)\n\n# Check it out\nstudents_3\n\n  student    class grade\n1       Y COMP 101     B\n2       Y BIOL 101     S\n3       Z POLI 101     C\n4       Z COMP 101     A\n\n\n\nCode# Add average grades in each course\nenrollments_3 &lt;- data.frame(\n  class = c(\"ART 101\", \"BIOL 101\",\"COMP 101\"),\n  grade = c(\"B\", \"A\", \"A-\"),\n  enrollment = c(20, 18, 19)\n)\n\n# Check it out\nenrollments_3\n\n     class grade enrollment\n1  ART 101     B         20\n2 BIOL 101     A         18\n3 COMP 101    A-         19\n\n\nTry doing a left_join() to link the students’ classes to their enrollment info. Did this work? Try and figure out the culprit by examining the output.\n\nCodestudents_3 |&gt; \n  left_join(enrollments_3)\n\n  student    class grade enrollment\n1       Y COMP 101     B         NA\n2       Y BIOL 101     S         NA\n3       Z POLI 101     C         NA\n4       Z COMP 101     A         NA\n\n\n\n14.1.0.4 Part d\nThe issue here is that our datasets have 2 column names in common: class and grade. BUT grade is measuring 2 different things here: individual student grades in students_3 and average student grades in enrollments_3. Thus it doesn’t make sense to try to join the datasets with respect to this variable. We can again solve this by specifying that we want to join the datasets using the class variable as a key. What are grade.x and grade.y?\n\nCodestudents_3 |&gt; \n  left_join(enrollments_3, join_by(class == class))\n\n  student    class grade.x grade.y enrollment\n1       Y COMP 101       B      A-         19\n2       Y BIOL 101       S       A         18\n3       Z POLI 101       C    &lt;NA&gt;         NA\n4       Z COMP 101       A      A-         19",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#exercise-2",
    "href": "ica/ica-joining.html#exercise-2",
    "title": "\n14  Joining\n",
    "section": "\n14.2 Exercise 2",
    "text": "14.2 Exercise 2\nBefore applying these ideas to bigger datasets, let’s practice identifying which join is appropriate in different scenarios. Define the following fake data on voters (people who have voted) and contact info for voting age adults (people who could vote):\n\nCode# People who have voted\nvoters &lt;- data.frame(\n  id = c(\"A\", \"D\", \"E\", \"F\", \"G\"),\n  times_voted = c(2, 4, 17, 6, 20)\n)\n\nvoters\n\n  id times_voted\n1  A           2\n2  D           4\n3  E          17\n4  F           6\n5  G          20\n\n\n\nCode# Contact info for voting age adults\ncontact &lt;- data.frame(\n  name = c(\"A\", \"B\", \"C\", \"D\"),\n  address = c(\"summit\", \"grand\", \"snelling\", \"fairview\"),\n  age = c(24, 89, 43, 38)\n)\n\ncontact\n\n  name  address age\n1    A   summit  24\n2    B    grand  89\n3    C snelling  43\n4    D fairview  38\n\n\nUse the appropriate join for each prompt below. In each case, think before you type:\nWhat dataset goes on the left? What do you want the resulting dataset to look like? How many rows and columns will it have?\n\nCode# 1. We want contact info for people who HAVEN'T voted\ncontact |&gt; \n  anti_join(voters, join_by(name == id))\n\n  name  address age\n1    B    grand  89\n2    C snelling  43\n\nCode# 2. We want contact info for people who HAVE voted\ncontact |&gt; \n  semi_join(voters, join_by(name == id))\n\n  name  address age\n1    A   summit  24\n2    D fairview  38\n\nCode# 3. We want any data available on each person\ncontact |&gt; \n  full_join(voters, join_by(name == id))\n\n  name  address age times_voted\n1    A   summit  24           2\n2    B    grand  89          NA\n3    C snelling  43          NA\n4    D fairview  38           4\n5    E     &lt;NA&gt;  NA          17\n6    F     &lt;NA&gt;  NA           6\n7    G     &lt;NA&gt;  NA          20\n\nCode# 4. When possible, we want to add contact info to the voting roster\nvoters |&gt; \n  left_join(contact, join_by(id == name))\n\n  id times_voted  address age\n1  A           2   summit  24\n2  D           4 fairview  38\n3  E          17     &lt;NA&gt;  NA\n4  F           6     &lt;NA&gt;  NA\n5  G          20     &lt;NA&gt;  NA",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#exercise-3",
    "href": "ica/ica-joining.html#exercise-3",
    "title": "\n14  Joining\n",
    "section": "\n14.3 Exercise 3",
    "text": "14.3 Exercise 3\nLet’s apply these ideas to some bigger datasets. In grades, each row is a student-class pair with information on:\nsid = student ID grade = student’s grade sessionID = an identifier of the class section\n\nCode# Get rid of some duplicate rows!\ngrades &lt;- read.csv(\"https://mac-stat.github.io/data/grades.csv\") |&gt; \n  distinct(sid, sessionID, .keep_all = TRUE)\nhead(grades)\n\n     sid grade   sessionID\n1 S31185    D+ session1784\n2 S31185    B+ session1785\n3 S31185    A- session1791\n4 S31185    B+ session1792\n5 S31185    B- session1794\n6 S31185    C+ session1795\n\nCodecourses &lt;- read.csv(\"https://mac-stat.github.io/data/courses.csv\") |&gt; \n  distinct(sessionID, dept, level, sem, enroll, iid,.keep_all = TRUE)\nhead(courses)\n\n    sessionID dept level    sem enroll     iid\n1 session1784    M   100 FA1991     22 inst265\n2 session1785    k   100 FA1991     52 inst458\n3 session1791    J   100 FA1993     22 inst223\n4 session1792    J   300 FA1993     20 inst235\n5 session1794    J   200 FA1993     22 inst234\n6 session1795    J   200 SP1994     26 inst230\n\n\nIn courses, each row corresponds to a class section with information on:\nsessionID = an identifier of the class section dept = department level = course level (eg: 100) sem = semester enroll = enrollment (number of students) iid = instructor ID\nUse R code to take a quick glance at the data.\n\nCode# How many observations (rows) and variables (columns) are there in the grades data?\ndim(grades)\n\n[1] 5844    3\n\nCode# How many observations (rows) and variables (columns) are there in the courses data?\ndim(courses)\n\n[1] 1718    6",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#exercise-4",
    "href": "ica/ica-joining.html#exercise-4",
    "title": "\n14  Joining\n",
    "section": "\n14.4 Exercise 4",
    "text": "14.4 Exercise 4\n\n14.4.0.1 Part a\n\nCodecourses |&gt; \n  count(sessionID) |&gt; \n  filter(n &gt; 1)\n\n     sessionID n\n1  session2047 2\n2  session2067 2\n3  session2448 2\n4  session2509 2\n5  session2541 2\n6  session2824 2\n7  session2826 2\n8  session2862 2\n9  session2897 2\n10 session3046 2\n11 session3057 2\n12 session3123 2\n13 session3243 2\n14 session3257 2\n15 session3387 2\n16 session3400 2\n17 session3414 2\n18 session3430 2\n19 session3489 2\n20 session3524 2\n21 session3629 2\n22 session3643 2\n23 session3821 2\n\n\nIf we pick out just 1 of these, we learn that some courses are cross-listed in multiple departments:\n\nCodecourses |&gt; \n  filter(sessionID == \"session2047\")\n\n    sessionID dept level    sem enroll     iid\n1 session2047    g   100 FA2001     12 inst436\n2 session2047    m   100 FA2001     28 inst436\n\n\nFor our class size exploration, obtain the total enrollments in each sessionID, combining any cross-listed sections. Save this as courses_combined. NOTE: There’s no joining to do here!\n\nCode courses_combined &lt;- courses |&gt; \n   group_by(sessionID) |&gt; \n   summarize(enroll = sum(enroll))\n\n# Check that this has 1695 rows and 2 columns\n dim(courses_combined)\n\n[1] 1695    2\n\n\n\n14.4.0.2 Part b\nLet’s first examine the question of class size from the administration’s viewpoint. To this end, calculate the median class size across all class sections. (The median is the middle or 50th percentile. Unlike the mean, it’s not skewed by outliers.) THINK FIRST:\nWhich of the 2 datasets do you need to answer this question? One? Both? If you need course information, use courses_combined not courses. Do you have to do any joining? If so, which dataset will go on the left, i.e. which dataset includes your primary observations of interest? Which join function will you need?\n\nCodecourses_combined |&gt; \n  summarize(median(enroll))\n\n# A tibble: 1 × 1\n  `median(enroll)`\n             &lt;int&gt;\n1               18\n\n\n\n14.4.0.3 Part c\nBut how big are classes from the student perspective? To this end, calculate the median class size for each individual student. Once you have the correct output, store it as student_class_size. THINK FIRST:\nWhich of the 2 datasets do you need to answer this question? One? Both? If you need course information, use courses_combined not courses. Do you have to do any joining? If so, which dataset will go on the left, i.e. which dataset includes your primary observations of interest? Which join function will you need?\n\nCodestudent_class_size &lt;- grades |&gt; \n  left_join(courses_combined) |&gt; \n  group_by(sid) |&gt; \n  summarize(med_class = median(enroll))\n\nhead(student_class_size)\n\n# A tibble: 6 × 2\n  sid    med_class\n  &lt;chr&gt;      &lt;dbl&gt;\n1 S31185      23.5\n2 S31188      21  \n3 S31191      25  \n4 S31194      15  \n5 S31197      24  \n6 S31200      21  \n\n\n\n14.4.0.4 Part d\nThe median class size varies from student to student. To get a sense for the typical student experience and range in student experiences, construct and discuss a histogram of the median class sizes experienced by the students.\n\nCode ggplot(student_class_size, aes(x = med_class)) + \n   geom_histogram()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#exercise-5",
    "href": "ica/ica-joining.html#exercise-5",
    "title": "\n14  Joining\n",
    "section": "\n14.5 Exercise 5",
    "text": "14.5 Exercise 5\n\n14.5.0.1 Part a\nShow data on the students that enrolled in session1986. THINK FIRST: Which of the 2 datasets do you need to answer this question? One? Both?\n\nCodegrades |&gt; \n  filter(sessionID == \"session1986\")\n\n     sid grade   sessionID\n1 S31401    B+ session1986\n2 S32247     B session1986\n\n\n\n14.5.0.2 Part b\n\nCodedept_E &lt;- courses |&gt; \n  filter(dept == \"E\")\n\n\nWhat students enrolled in classes in department E? (We just want info on the students, not the classes.)\n\nCodegrades |&gt; \n  semi_join(dept_E)\n\n      sid grade   sessionID\n1  S31245     A session2326\n2  S31470     B session3658\n3  S31470     B session3798\n4  S31470     A session3799\n5  S31938     A session2326\n6  S31968     A session3104\n7  S32022     A session3798\n8  S32046    A- session2326\n9  S32226     A session2326\n10 S32415     B session2835\n11 S32415    B+ session3799\n12 S32484    A- session3658",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#exercise-6",
    "href": "ica/ica-joining.html#exercise-6",
    "title": "\n14  Joining\n",
    "section": "\n14.6 Exercise 6",
    "text": "14.6 Exercise 6\nUse all of your wrangling skills to answer the following prompts! THINK FIRST:\nThink about what tables you might need to join (if any). Identify the corresponding variables to match. You’ll need an extra table to convert grades to grade point averages:\n\nCodegpa_conversion &lt;- tibble(\n  grade = c(\"A+\", \"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"AU\", \"S\"), \n  gpa = c(4.3, 4, 3.7, 3.3, 3, 2.7, 2.3, 2, 1.7, 1.3, 1, 0.7, 0, NA, NA)\n)\n\ngpa_conversion\n\n# A tibble: 15 × 2\n   grade   gpa\n   &lt;chr&gt; &lt;dbl&gt;\n 1 A+      4.3\n 2 A       4  \n 3 A-      3.7\n 4 B+      3.3\n 5 B       3  \n 6 B-      2.7\n 7 C+      2.3\n 8 C       2  \n 9 C-      1.7\n10 D+      1.3\n11 D       1  \n12 D-      0.7\n13 NC      0  \n14 AU     NA  \n15 S      NA  \n\n\n\n14.6.0.1 Part a\nHow many total student enrollments are there in each department? Order from high to low.\n\nCodecourses |&gt; \n  group_by(dept) |&gt; \n  summarize(total = sum(enroll)) |&gt; \n  arrange(desc(total))\n\n# A tibble: 40 × 2\n   dept  total\n   &lt;chr&gt; &lt;int&gt;\n 1 d      3046\n 2 j      2312\n 3 O      2178\n 4 M      2129\n 5 m      2105\n 6 D      2003\n 7 W      1960\n 8 q      1859\n 9 k      1824\n10 F      1587\n# ℹ 30 more rows\n\n\n\n14.6.0.2 Part b\nWhat’s the grade-point average (GPA) for each student?\n\nCodegrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(sid) |&gt; \n  summarize(mean(gpa, na.rm = TRUE))\n\n# A tibble: 443 × 2\n   sid    `mean(gpa, na.rm = TRUE)`\n   &lt;chr&gt;                      &lt;dbl&gt;\n 1 S31185                      2.41\n 2 S31188                      3.02\n 3 S31191                      3.21\n 4 S31194                      3.36\n 5 S31197                      3.35\n 6 S31200                      2.2 \n 7 S31203                      3.82\n 8 S31206                      2.46\n 9 S31209                      3.13\n10 S31212                      3.67\n# ℹ 433 more rows\n\n\n\n14.6.0.3 Part c\nWhat’s the median GPA across all students?\n\nCodegrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(sid) |&gt; \n  summarize(gpa = mean(gpa, na.rm = TRUE)) |&gt; \n  summarize(median(gpa))\n\n# A tibble: 1 × 1\n  `median(gpa)`\n          &lt;dbl&gt;\n1          3.47\n\n\n\n14.6.0.4 Part d\nWhat fraction of grades are below B+?\n\nCode# There are lots of approaches here!\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  mutate(below_b_plus = (gpa &lt; 3.3)) |&gt; \n  summarize(mean(below_b_plus, na.rm = TRUE))\n\n  mean(below_b_plus, na.rm = TRUE)\n1                        0.2834776\n\n\n\n14.6.0.5 Part e\nWhat’s the grade-point average for each instructor? Order from low to high.\n\nCodegrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  left_join(courses) |&gt; \n  group_by(iid) |&gt; \n  summarize(gpa = mean(gpa, na.rm = TRUE)) |&gt; \n  arrange(gpa)\n\n# A tibble: 364 × 2\n   iid       gpa\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 inst265  1.3 \n 2 inst444  1.7 \n 3 inst513  1.85\n 4 inst200  2   \n 5 inst507  2.2 \n 6 inst445  2.3 \n 7 inst420  2.6 \n 8 inst262  2.65\n 9 inst176  2.66\n10 inst234  2.7 \n# ℹ 354 more rows\n\n\n\n14.6.0.6 Part f\nCHALLENGE: Estimate the grade-point average for each department, and sort from low to high. NOTE: Don’t include cross-listed courses. Students in cross-listed courses could be enrolled under either department, and we do not know which department to assign the grade to. HINT: You’ll need to do multiple joins.\n\nCodecross_listed &lt;- courses |&gt; \n  count(sessionID) |&gt; \n  filter(n &gt; 1)\n\ngrades |&gt; \n  anti_join(cross_listed) |&gt; \n  inner_join(courses) |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(dept) |&gt; \n  summarize(gpa = mean(gpa, na.rm = TRUE)) |&gt; \n  arrange(gpa)\n\n# A tibble: 39 × 2\n   dept    gpa\n   &lt;chr&gt; &lt;dbl&gt;\n 1 o      3.08\n 2 M      3.10\n 3 K      3.17\n 4 G      3.18\n 5 B      3.2 \n 6 J      3.22\n 7 T      3.23\n 8 b      3.25\n 9 F      3.30\n10 d      3.31\n# ℹ 29 more rows",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-factors.html",
    "href": "ica/ica-factors.html",
    "title": "\n15  Factors\n",
    "section": "",
    "text": "15.1 Exercise 1\nCodelibrary(tidyverse)\n# Get rid of some duplicate rows!\ngrades &lt;- read.csv(\"https://mac-stat.github.io/data/grades.csv\") |&gt; \n  distinct(sid, sessionID, .keep_all = TRUE)\n\n# Check it out\nhead(grades)\n\n     sid grade   sessionID\n1 S31185    D+ session1784\n2 S31185    B+ session1785\n3 S31185    A- session1791\n4 S31185    B+ session1792\n5 S31185    B- session1794\n6 S31185    C+ session1795\nCodegrade_distribution &lt;- grades |&gt; \n  count(grade)\n\nhead(grade_distribution)\n\n  grade    n\n1     A 1506\n2    A- 1381\n3    AU   27\n4     B  804\n5    B+ 1003\n6    B-  330",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "ica/ica-factors.html#exercise-1",
    "href": "ica/ica-factors.html#exercise-1",
    "title": "\n15  Factors\n",
    "section": "",
    "text": "15.1.0.1 Part a\n\nCodegrade_distribution |&gt; \n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\n\n\n\n\n\n\n\n\n15.1.0.2 Part b\nThe order of the grades is goofy! Construct a new column plot, manually reordering the grades from high (A) to low (NC) with “S” and “AU” at the end:\n\nCode grade_distribution |&gt;\n   mutate(grade = fct_relevel(grade, c(\"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"S\", \"AU\"))) |&gt;\n   ggplot(aes(x = grade, y = n)) +\n     geom_col()\n\n\n\n\n\n\n\n\n15.1.0.3 Part c\nConstruct a new column plot, reordering the grades in ascending frequency (i.e. how often the grades were assigned):\n\nCode grade_distribution |&gt;\n   mutate(grade = fct_reorder(grade, n)) |&gt;\n   ggplot(aes(x = grade, y = n)) +\n     geom_col()\n\n\n\n\n\n\n\n\n15.1.0.4 Part d\nConstruct a new column plot, reordering the grades in descending frequency (i.e. how often the grades were assigned):\n\nCode grade_distribution |&gt;\n   mutate(grade = fct_reorder(grade, n, .desc = TRUE)) |&gt;\n   ggplot(aes(x = grade, y = n)) +\n     geom_col()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "ica/ica-factors.html#exercise-2",
    "href": "ica/ica-factors.html#exercise-2",
    "title": "\n15  Factors\n",
    "section": "\n15.2 Exercise 2",
    "text": "15.2 Exercise 2\nIt may not be clear what “AU” and “S” stand for. Construct a new column plot that renames these levels “Audit” and “Satisfactory”, while keeping the other grade labels the same and in a meaningful order:\n\nCode grade_distribution |&gt;\n   mutate(grade = fct_relevel(grade, c(\"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"S\", \"AU\"))) |&gt;\n   mutate(grade = fct_recode(grade,\"Satisfactory\" = \"S\", \"Audit\" = \"AU\")) |&gt;  # Multiple pieces go into the last 2 blanks\n   ggplot(aes(x = grade, y = n)) +\n     geom_col()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "ica/ica-strings.html",
    "href": "ica/ica-strings.html",
    "title": "\n16  Strings\n",
    "section": "",
    "text": "Essential Functions\nThe stringr package within tidyverse contains lots of functions to help process strings. We’ll focus on the most common. Letting x be a string variable…\n\n\nfunction\narguments\nreturns\n\n\n\nstr_replace()\nx, pattern, replacement\na modified string\n\n\nstr_replace_all()\nx, pattern, replacement\na modified string\n\n\nstr_to_lower()\nx\na modified string\n\n\nstr_sub()\nx, start, end\na modified string\n\n\nstr_length()\nx\na number\n\n\nstr_detect()\nx, pattern\nTRUE/FALSE\n\n\nSummary\nHere’s what we learned about each function:\n\nstr_replace(x, pattern, replacement) finds the first part of x that matches the pattern and replaces it with replacement\nstr_replace_all(x, pattern, replacement) finds all instances in x that matches the pattern and replaces it with replacement\nstr_to_lower(x) converts all upper case letters in x to lower case\nstr_sub(x, start, end) only keeps a subset of characters in x, from start (a number indexing the first letter to keep) to end (a number indexing the last letter to keep)\nstr_length(x) records the number of characters in x\nstr_detect(x, pattern) is TRUE if x contains the given pattern and FALSE otherwise\nExercise 1: Time slots\nThe courses data includes actual data scraped from Mac’s class schedule. (Thanks to Prof Leslie Myint for the scraping code!!)\nIf you want to learn how to scrape data, take COMP/STAT 212, Intermediate Data Science! NOTE: For simplicity, I removed classes that had “TBA” for the days.\n\nCodelibrary(tidyverse)\nlibrary(ggplot2)\ncourses &lt;- read.csv(\"https://mac-stat.github.io/data/registrar.csv\")\n\n# Check it out\nhead(courses)\n\n       number   crn                                                name  days\n1 AMST 112-01 10318         Introduction to African American Literature M W F\n2 AMST 194-01 10073              Introduction to Asian American Studies M W F\n3 AMST 194-F1 10072 What’s After White Empire - And Is It Already Here?  T R \n4 AMST 203-01 10646 Politics and Inequality: The American Welfare State M W F\n5 AMST 205-01 10842                         Trans Theories and Politics  T R \n6 AMST 209-01 10474                   Civil Rights in the United States   W  \n             time      room             instructor avail_max\n1 9:40 - 10:40 am  MAIN 009       Daylanne English    3 / 20\n2  1:10 - 2:10 pm MUSIC 219          Jake Nagasawa   -4 / 16\n3  3:00 - 4:30 pm   HUM 214 Karin Aguilar-San Juan    0 / 14\n4 9:40 - 10:40 am  CARN 305          Lesley Lavery    3 / 25\n5  3:00 - 4:30 pm  MAIN 009              Myrl Beam   -2 / 20\n6 7:00 - 10:00 pm  MAIN 010         Walter Greason   -1 / 15\n\n\nUse our more familiar wrangling tools to warm up.\n\nCode# Construct a table that indicates the number of classes offered in each day/time slot\ncourses |&gt; \n  count(days, time) |&gt; \n  arrange(desc(n)) |&gt; \n  head()\n\n   days             time  n\n1 M W F 10:50 - 11:50 am 76\n2  T R   9:40 - 11:10 am 71\n3 M W F  9:40 - 10:40 am 68\n4 M W F   1:10 - 2:10 pm 66\n5  T R    3:00 - 4:30 pm 62\n6  T R    1:20 - 2:50 pm 59\n\n\nExercise 2: Prep the data\nSo that we can analyze it later, we want to wrangle the courses data:\n\nLet’s get some enrollment info:\n\nSplit avail_max into 2 separate variables: avail and max.\nUse avail and max to define a new variable called enroll. HINT: You’ll need as.numeric()\n\n\n\nSplit the course number into 3 separate variables: dept, number, and section. HINT: You can use separate() to split a variable into 3, not just 2 new variables.\n\nStore this as courses_clean so that you can use it later.\n\nCodecourses_clean &lt;- courses |&gt; \n  separate(avail_max, c(\"avail\", \"max\"), sep = \" / \") |&gt; \n  mutate(enroll = as.numeric(max) - as.numeric(avail)) |&gt; \n  separate(number, c(\"dept\", \"number\", \"section\"))\n  \nhead(courses_clean)\n\n  dept number section   crn                                                name\n1 AMST    112      01 10318         Introduction to African American Literature\n2 AMST    194      01 10073              Introduction to Asian American Studies\n3 AMST    194      F1 10072 What’s After White Empire - And Is It Already Here?\n4 AMST    203      01 10646 Politics and Inequality: The American Welfare State\n5 AMST    205      01 10842                         Trans Theories and Politics\n6 AMST    209      01 10474                   Civil Rights in the United States\n   days            time      room             instructor avail max enroll\n1 M W F 9:40 - 10:40 am  MAIN 009       Daylanne English     3  20     17\n2 M W F  1:10 - 2:10 pm MUSIC 219          Jake Nagasawa    -4  16     20\n3  T R   3:00 - 4:30 pm   HUM 214 Karin Aguilar-San Juan     0  14     14\n4 M W F 9:40 - 10:40 am  CARN 305          Lesley Lavery     3  25     22\n5  T R   3:00 - 4:30 pm  MAIN 009              Myrl Beam    -2  20     22\n6   W   7:00 - 10:00 pm  MAIN 010         Walter Greason    -1  15     16\n\n\nExercise 3: Courses by department\nUsing courses_clean…\n\nCode# Identify the 6 departments that offered the most sections\ncourses_clean |&gt; \n  count(dept) |&gt; \n  arrange(desc(n)) |&gt; \n  head()\n\n  dept  n\n1 SPAN 45\n2 BIOL 44\n3 ENVI 38\n4 PSYC 37\n5 CHEM 33\n6 COMP 31\n\nCode# Identify the 6 departments with the longest average course titles\ncourses_clean |&gt; \n  mutate(length = str_length(name)) |&gt; \n  group_by(dept) |&gt; \n  summarize(avg_length = mean(length)) |&gt; \n  arrange(desc(avg_length)) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  dept  avg_length\n  &lt;chr&gt;      &lt;dbl&gt;\n1 WGSS        46.3\n2 INTL        41.4\n3 EDUC        39.4\n4 MCST        39.4\n5 POLI        37.4\n6 AMST        37.3\n\n\nExercise 4: STAT courses\nPart a\nGet a subset of courses_clean that only includes courses taught by Alicia Johnson.\n\nCodecourses_clean |&gt; \n  filter(str_detect(instructor, \"Alicia Johnson\")) \n\n  dept number section   crn                         name  days            time\n1 STAT    253      01 10806 Statistical Machine Learning  T R  9:40 - 11:10 am\n2 STAT    253      02 10807 Statistical Machine Learning  T R   1:20 - 2:50 pm\n3 STAT    253      03 10808 Statistical Machine Learning  T R   3:00 - 4:30 pm\n        room     instructor avail max enroll\n1 THEATR 206 Alicia Johnson    -3  20     23\n2 THEATR 206 Alicia Johnson    -3  20     23\n3 THEATR 206 Alicia Johnson     2  20     18\n\n\nPart b\nCreate a new dataset from courses_clean, named stat, that only includes STAT sections. In this dataset:\n\n\nIn the course names:\n\nRemove “Introduction to” from any name.\nShorten “Statistical” to “Stat” where relevant.\n\n\nDefine a variable that records the start_time for the course.\nKeep only the number, name, start_time, enroll columns.\nThe result should have 19 rows and 4 columns.\n\n\nCodestat &lt;- courses_clean |&gt; \n  filter(dept == \"STAT\") |&gt; \n  mutate(name = str_replace(name, \"Introduction to \", \"\")) |&gt;\n  mutate(name = str_replace(name, \"Statistical\", \"Stat\")) |&gt; \n  mutate(start_time = str_sub(time, 1, 5)) |&gt; \n  select(number, name, start_time, enroll)\n\nstat\n\n   number                      name start_time enroll\n1     112              Data Science      3:00      27\n2     112              Data Science      9:40      21\n3     112              Data Science      1:20      25\n4     125              Epidemiology      12:00     26\n5     155             Stat Modeling      1:10      32\n6     155             Stat Modeling      9:40      24\n7     155             Stat Modeling      10:50     26\n8     155             Stat Modeling      3:30      25\n9     155             Stat Modeling      1:20      30\n10    155             Stat Modeling      3:00      27\n11    212 Intermediate Data Science      9:40      11\n12    212 Intermediate Data Science      1:20      11\n13    253     Stat Machine Learning      9:40      23\n14    253     Stat Machine Learning      1:20      23\n15    253     Stat Machine Learning      3:00      18\n16    354               Probability      3:00      22\n17    452           Correlated Data      9:40       7\n18    452           Correlated Data      1:20       8\n19    456  Projects in Data Science      9:40      11\n\n\n\nCodedim(stat)\n\n[1] 19  4\n\n\nExercise 5: More cleaning\nIn the next exercises, we’ll dig into enrollments. Let’s get the data ready for that analysis here. Make the following changes to the courses_clean data. Because they have different enrollment structures, and we don’t want to compare apples and oranges, remove the following:\n\nall sections in PE and INTD (interdisciplinary studies courses)\nall music ensembles and dance practicums, i.e. all MUSI and THDA classes with numbers less than 100. HINT: !(dept == \"MUSI\" & as.numeric(number) &lt; 100)\nall lab sections. Be careful which variable you use here. For example, you don’t want to search by “Lab” and accidentally eliminate courses with words such as “Labor”.\n\nSave the results as enrollments (don’t overwrite courses_clean).\n\nCodeenrollments &lt;- courses_clean |&gt; \n  filter(dept != \"PE\", dept != \"INTD\") |&gt; \n  filter(!(dept == \"MUSI\" & as.numeric(number) &lt; 100)) |&gt; \n  filter(!(dept == \"THDA\" & as.numeric(number) &lt; 100)) |&gt; \n  filter(!str_detect(section, \"L\"))\n  \nhead(enrollments)\n\n  dept number section   crn                                                name\n1 AMST    112      01 10318         Introduction to African American Literature\n2 AMST    194      01 10073              Introduction to Asian American Studies\n3 AMST    194      F1 10072 What’s After White Empire - And Is It Already Here?\n4 AMST    203      01 10646 Politics and Inequality: The American Welfare State\n5 AMST    205      01 10842                         Trans Theories and Politics\n6 AMST    209      01 10474                   Civil Rights in the United States\n   days            time      room             instructor avail max enroll\n1 M W F 9:40 - 10:40 am  MAIN 009       Daylanne English     3  20     17\n2 M W F  1:10 - 2:10 pm MUSIC 219          Jake Nagasawa    -4  16     20\n3  T R   3:00 - 4:30 pm   HUM 214 Karin Aguilar-San Juan     0  14     14\n4 M W F 9:40 - 10:40 am  CARN 305          Lesley Lavery     3  25     22\n5  T R   3:00 - 4:30 pm  MAIN 009              Myrl Beam    -2  20     22\n6   W   7:00 - 10:00 pm  MAIN 010         Walter Greason    -1  15     16\n\n\nExercise 6: Enrollment & departments\nExplore enrollments by department. You decide what research questions to focus on. Use both visual and numerical summaries.\nExercise 7: Enrollment & faculty\nLet’s now explore enrollments by instructor. In doing so, we have to be cautious of cross-listed courses that are listed under multiple different departments. Uncomment the code lines in the chunk below for an example.\n\n\n\n\n\n\nCommenting/Uncommenting Code\n\n\n\nTo comment/uncomment several lines of code at once, highlight them then click ctrl/cmd+shift+c.\n\n\n\nCode# enrollments |&gt;\n#   filter(dept %in% c(\"STAT\", \"COMP\"), number == 112, section == \"01\")\n\n\nNotice that these are the exact same section! In order to not double count an instructor’s enrollments, we can keep only the courses that have distinct() combinations of days, time, instructor values. Uncomment the code lines in the chunk below.\n\nCode# enrollments_2 &lt;- enrollments |&gt; \n#   distinct(days, time, instructor, .keep_all = TRUE)\n\n# NOTE: By default this keeps the first department alphabetically\n# That's fine because we won't use this to analyze department enrollments!\n# enrollments_2 |&gt; \n#   filter(instructor == \"Brianna Heggeseth\", name == \"Introduction to Data Science\")\n\n\nNow, explore enrollments by instructor. You decide what research questions to focus on. Use both visual and numerical summaries.\nCAVEAT: The above code doesn’t deal with co-taught courses that have more than one instructor. Thus instructors that co-taught are recorded as a pair, and their co-taught enrollments aren’t added to their total enrollments. This is tough to get around with how the data were scraped as the instructor names are smushed together, not separated by a comma!\nOptional extra practice\n\nCode# Make a bar plot showing the number of night courses by day of the week\n# Use courses_clean\n\n# Make a bar plot showing the number of night courses by day of the week.\ncourses_clean |&gt; \n  filter(str_detect(time, \"7:00\")) |&gt; \n  ggplot(aes(x = days)) + \n    geom_bar()\n\n\n\n\n\n\n\nDig Deeper: regex\nExample 4 gave 1 small example of a regular expression.\nThese are handy when we want process a string variable, but there’s no consistent pattern by which to do this. You must think about the structure of the string and how you can use regular expressions to capture the patterns you want (and exclude the patterns you don’t want).\nFor example, how would you describe the pattern of a 10-digit phone number? Limit yourself to just a US phone number for now.\n\nThe first 3 digits are the area code.\nThe next 3 digits are the exchange code.\nThe last 4 digits are the subscriber number.\n\nThus, a regular expression for a US phone number could be:\n\n\n[:digit:]{3}-[:digit:]{3}-[:digit:]{4} which limits you to XXX-XXX-XXXX pattern or\n\n\\\\([:digit:]{3}\\\\) [:digit:]{3}-[:digit:]{4} which limits you to (XXX) XXX-XXXX pattern or\n\n[:digit:]{3}\\\\.[:digit:]{3}\\\\.[:digit:]{4} which limits you to XXX.XXX.XXXX pattern\n\nThe following would include the three patterns above in addition to the XXXXXXXXXX pattern (no dashes or periods): - [\\\\(]*[:digit:]{3}[-.\\\\)]*[:digit:]{3}[-.]*[:digit:]{4}\nIn order to write a regular expression, you first need to consider what patterns you want to include and exclude.\nWork through the following examples, and the tutorial after them to learn about the syntax.\nEXAMPLES\n\nCode# Define some strings to play around with\nexample &lt;- \"The quick brown fox jumps over the lazy dog.\"\n\n\n\nCodestr_replace(example, \"quick\", \"really quick\")\n\n[1] \"The really quick brown fox jumps over the lazy dog.\"\n\n\n\nCodestr_replace_all(example, \"(fox|dog)\", \"****\") # | reads as OR\n\n[1] \"The quick brown **** jumps over the lazy ****.\"\n\n\n\nCodestr_replace_all(example, \"(fox|dog).\", \"****\") # \".\" for any character\n\n[1] \"The quick brown ****jumps over the lazy ****\"\n\n\n\nCodestr_replace_all(example, \"(fox|dog)\\\\.$\", \"****\") # at end of sentence only, \"\\\\.\" only for a period\n\n[1] \"The quick brown fox jumps over the lazy ****\"\n\n\n\nCodestr_replace_all(example, \"the\", \"a\") # case-sensitive only matches one\n\n[1] \"The quick brown fox jumps over a lazy dog.\"\n\n\n\nCodestr_replace_all(example, \"[Tt]he\", \"a\") # # will match either t or T; could also make \"a\" conditional on capitalization of t\n\n[1] \"a quick brown fox jumps over a lazy dog.\"\n\n\n\nCodestr_replace_all(example, \"[Tt]he\", \"a\") # first match only\n\n[1] \"a quick brown fox jumps over a lazy dog.\"\n\n\n\nCode# More examples\nexample2 &lt;- \"Two roads diverged in a yellow wood, / And sorry I could not travel both / And be one traveler, long I stood / And looked down one as far as I could\"\nexample3 &lt;- \"This is a test\"\n\n# Store the examples in 1 place\nexamples &lt;- c(example, example2, example3)\n\n\n\nCodepat &lt;- \"[^aeiouAEIOU ]{3}\" # Regular expression for three straight consonants. Note that I've excluded spaces as well\n\nstr_detect(examples, pat) # TRUE/FALSE if it detects pattern\n\n[1]  TRUE  TRUE FALSE\n\n\n\nCodestr_subset(examples, pat) # Pulls out those that detects pattern\n\n[1] \"The quick brown fox jumps over the lazy dog.\"                                                                                                        \n[2] \"Two roads diverged in a yellow wood, / And sorry I could not travel both / And be one traveler, long I stood / And looked down one as far as I could\"\n\n\n\nCodepat2 &lt;- \"[^aeiouAEIOU ][aeiouAEIOU]{2}[^aeiouAEIOU ]{1}\" # consonant followed by two vowels followed by a consonant\n\nstr_extract(example2, pat2) # extract first match\n\n[1] \"road\"\n\n\n\nCodestr_extract_all(example2, pat2, simplify = TRUE) # extract all matches\n\n     [,1]   [,2]   [,3]   [,4]   [,5]   [,6]  \n[1,] \"road\" \"wood\" \"coul\" \"tood\" \"look\" \"coul\"",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "ica/ica-data import.html",
    "href": "ica/ica-data import.html",
    "title": "\n17  Data Import\n",
    "section": "",
    "text": "17.1 Exercise 1: Save data locally",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Import</span>"
    ]
  },
  {
    "objectID": "ica/ica-data import.html#exercise-1-save-data-locally",
    "href": "ica/ica-data import.html#exercise-1-save-data-locally",
    "title": "\n17  Data Import\n",
    "section": "",
    "text": "17.1.0.1 Part a\nOn your laptop:\nDownload the “imdb_5000_messy.csv” file from Moodle Move it to the data folder in your portfolio repository\n\n17.1.0.2 Part b\nHot tip: After saving your data file, it’s important to record appropriate citations and info in either a new qmd (eg: “imdb_5000_messy_README.qmd”) or in the qmd where you’ll analyze the data. These citations should include:\nthe data source, i.e. where you found the data the data creator, i.e. who / what group collected the original data possibly a data codebook, i.e. descriptions of the data variables To this end, check out where we originally got our IMDB data:\nhttps://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata\nAfter visiting that website, take some quick notes here on the data source and creator.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Import</span>"
    ]
  },
  {
    "objectID": "ica/ica-data import.html#exercise-2-import-data-to-rstudio",
    "href": "ica/ica-data import.html#exercise-2-import-data-to-rstudio",
    "title": "\n17  Data Import\n",
    "section": "\n17.2 Exercise 2: Import Data to RStudio",
    "text": "17.2 Exercise 2: Import Data to RStudio\nNow that we have a local copy of our data file, let’s get it into RStudio! Remember that this process depends on 2 things: the file type and location. Since our file type is a csv, we can import it using read_csv(). But we have to supply the file location through a file path. To this end, we can either use an absolute file path or a relative file path.\n\n17.2.0.1 Part a\nAn absolute file path describes the location of a file starting from the root or home directory. How we refer to the user root directory depends upon your machine:\nOn a Mac: ~ On Windows: typically C:\nThen the complete file path to the IMDB data file in the data folder, depending on your machine an where you created your portfolio project, can be:\nOn a Mac: ~/Desktop/portfolio/data/imdb_5000_messy.csv On Windows: C:_5000_messy.csv or C:\\Desktop\\portfolio\\data\\imdb_5000_messy.csv Putting this together, use read_csv() with the appropriate absolute file path to import your data into RStudio. Save this as imdb_messy.\n\nCodelibrary(tidyverse)\n imdb_messy &lt;- read_csv(\"~/Documents/GitHub/portfolio-2saB/data/imdb_5000_messy.csv\")\n\n\n\n17.2.0.2 Part b\nAbsolute file paths can get really long, depending upon our number of sub-folders, and they should not be used when sharing code with other and instead relative file paths should be used. A relative file path describes the location of a file from the current “working directory”, i.e. where RStudio would currently look for on your computer. Check what your working directory is inside this qmd:\n\nCode# This should be the folder where you stored this qmd!\ngetwd()\n\n[1] \"/Users/2sa/Documents/GitHub/portfolio-2saB/ica\"\n\n\nNext, check what the working directory is for the console by typing getwd() in the console. This is probably different, meaning that the relative file paths that will work in your qmd won’t work in the console! You can either exclusively work inside your qmd, or change the working directory in your console, by navigating to the following in the upper toolbar: Session &gt; Set Working Directory &gt; To Source File location.\n\n17.2.0.3 Part c\nAs a good practice, we created a data folder and saved our data file (imdb_5000_messy.csv) into.\nSince our .qmd analysis and .csv data live in the same project, we don’t have to write out absolute file paths that go all the way to the root directory. We can use relative file paths that start from where our code file exists to where the data file exist:\nOn a Mac: ../data/imdb_5000_messy.csv On Windows: .._5000_messy.csv or ..\\data\\imdb_5000_messy.csv NOTE: .. means go up one level in the file hierarchy, ie, go to the parent folder/directory.\nPutting this together, use read_csv() with the appropriate relative file path to import your data into RStudio. Save this as imdb_temp (temp for “temporary”). Convince yourself that this worked, i.e. you get the same dataset as imdb_messy.\n\nCodeimdb_temp &lt;- read_csv(\"../data/imdb_5000_messy.csv\")\n\n\n\n17.2.0.4 Part d: OPTIONAL\nSometimes, we don’t want to import the entire dataset. For example, we might want to…\nskips some rows, eg, if they’re just “filler” only import the first “n” rows, eg, if the dataset is really large only import a random subset of “n” rows, eg, if the dataset is really large The “data import cheat sheet” at the top of this qmd, or Google, are handy resources here. As one example…\n\nCode# Try importing only the first 5 rows\n read_csv(\"../data/imdb_5000_messy.csv\", n_max = 5)\n\n# A tibble: 5 × 29\n   ...1 color director_name     num_critic_for_reviews duration\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                              &lt;dbl&gt;    &lt;dbl&gt;\n1     1 Color James Cameron                        723      178\n2     2 Color Gore Verbinski                       302      169\n3     3 Color Sam Mendes                           602      148\n4     4 Color Christopher Nolan                    813      164\n5     5 &lt;NA&gt;  Doug Walker                           NA       NA\n# ℹ 24 more variables: director_facebook_likes &lt;dbl&gt;,\n#   actor_3_facebook_likes &lt;dbl&gt;, actor_2_name &lt;chr&gt;,\n#   actor_1_facebook_likes &lt;dbl&gt;, gross &lt;dbl&gt;, genres &lt;chr&gt;,\n#   actor_1_name &lt;chr&gt;, movie_title &lt;chr&gt;, num_voted_users &lt;dbl&gt;,\n#   cast_total_facebook_likes &lt;dbl&gt;, actor_3_name &lt;chr&gt;,\n#   facenumber_in_poster &lt;dbl&gt;, plot_keywords &lt;chr&gt;, movie_imdb_link &lt;chr&gt;,\n#   num_user_for_reviews &lt;dbl&gt;, language &lt;chr&gt;, country &lt;chr&gt;, …",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Import</span>"
    ]
  },
  {
    "objectID": "ica/ica-data import.html#exercise-3-check-data",
    "href": "ica/ica-data import.html#exercise-3-check-data",
    "title": "\n17  Data Import\n",
    "section": "\n17.3 Exercise 3: Check Data",
    "text": "17.3 Exercise 3: Check Data\nAfter importing new data into RStudio, you MUST do some quick checks of the data. Here are two first steps that are especially useful.\n\n17.3.0.1 Part a\nOpen imdb_messy in the spreadsheet-like viewer by typing View(imdb_messy) in the console. Sort this “spreadsheet” by different variables by clicking on the arrows next to the variable names. Do you notice anything unexpected?\n\n17.3.0.2 Part b\nDo a quick summary() of each variable in the dataset. One way to do this is below:\n\nCode imdb_messy |&gt;\n   mutate(across(where(is.character), as.factor)) |&gt;  # convert characters to factors in order to summarize\n   summary()\n\n      ...1                  color               director_name \n Min.   :   1   B&W            :  10   Steven Spielberg:  26  \n 1st Qu.:1262   Black and White: 199   Woody Allen     :  22  \n Median :2522   color          :  30   Clint Eastwood  :  20  \n Mean   :2522   Color          :4755   Martin Scorsese :  20  \n 3rd Qu.:3782   COLOR          :  30   Ridley Scott    :  17  \n Max.   :5043   NA's           :  19   (Other)         :4834  \n                                       NA's            : 104  \n num_critic_for_reviews    duration     director_facebook_likes\n Min.   :  1.0          Min.   :  7.0   Min.   :    0.0        \n 1st Qu.: 50.0          1st Qu.: 93.0   1st Qu.:    7.0        \n Median :110.0          Median :103.0   Median :   49.0        \n Mean   :140.2          Mean   :107.2   Mean   :  686.5        \n 3rd Qu.:195.0          3rd Qu.:118.0   3rd Qu.:  194.5        \n Max.   :813.0          Max.   :511.0   Max.   :23000.0        \n NA's   :50             NA's   :15      NA's   :104            \n actor_3_facebook_likes          actor_2_name  actor_1_facebook_likes\n Min.   :    0.0        Morgan Freeman :  20   Min.   :     0        \n 1st Qu.:  133.0        Charlize Theron:  15   1st Qu.:   614        \n Median :  371.5        Brad Pitt      :  14   Median :   988        \n Mean   :  645.0        James Franco   :  11   Mean   :  6560        \n 3rd Qu.:  636.0        Meryl Streep   :  11   3rd Qu.: 11000        \n Max.   :23000.0        (Other)        :4959   Max.   :640000        \n NA's   :23             NA's           :  13   NA's   :7             \n     gross                            genres             actor_1_name \n Min.   :      162   Drama               : 236   Robert De Niro:  49  \n 1st Qu.:  5340988   Comedy              : 209   Johnny Depp   :  41  \n Median : 25517500   Comedy|Drama        : 191   Nicolas Cage  :  33  \n Mean   : 48468408   Comedy|Drama|Romance: 187   J.K. Simmons  :  31  \n 3rd Qu.: 62309438   Comedy|Romance      : 158   Bruce Willis  :  30  \n Max.   :760505847   Drama|Romance       : 152   (Other)       :4852  \n NA's   :884         (Other)             :3910   NA's          :   7  \n                    movie_title   num_voted_users   cast_total_facebook_likes\n Ben-Hur                  :   3   Min.   :      5   Min.   :     0           \n Halloween                :   3   1st Qu.:   8594   1st Qu.:  1411           \n Home                     :   3   Median :  34359   Median :  3090           \n King Kong                :   3   Mean   :  83668   Mean   :  9699           \n Pan                      :   3   3rd Qu.:  96309   3rd Qu.: 13756           \n The Fast and the Furious :   3   Max.   :1689764   Max.   :656730           \n (Other)                  :5025                                              \n         actor_3_name  facenumber_in_poster\n Ben Mendelsohn:   8   Min.   : 0.000      \n John Heard    :   8   1st Qu.: 0.000      \n Steve Coogan  :   8   Median : 1.000      \n Anne Hathaway :   7   Mean   : 1.371      \n Jon Gries     :   7   3rd Qu.: 2.000      \n (Other)       :4982   Max.   :43.000      \n NA's          :  23   NA's   :13          \n                                                                           plot_keywords \n based on novel                                                                   :   4  \n 1940s|child hero|fantasy world|orphan|reference to peter pan                     :   3  \n alien friendship|alien invasion|australia|flying car|mother daughter relationship:   3  \n animal name in title|ape abducts a woman|gorilla|island|king kong                :   3  \n assistant|experiment|frankenstein|medical student|scientist                      :   3  \n (Other)                                                                          :4874  \n NA's                                                                             : 153  \n                                             movie_imdb_link\n http://www.imdb.com/title/tt0077651/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt0232500/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt0360717/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt1976009/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt2224026/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt2638144/?ref_=fn_tt_tt_1:   3  \n (Other)                                             :5025  \n num_user_for_reviews     language       country       content_rating\n Min.   :   1.0       English :4704   USA    :3807   R        :2118  \n 1st Qu.:  65.0       French  :  73   UK     : 448   PG-13    :1461  \n Median : 156.0       Spanish :  40   France : 154   PG       : 701  \n Mean   : 272.8       Hindi   :  28   Canada : 126   Not Rated: 116  \n 3rd Qu.: 326.0       Mandarin:  26   Germany:  97   G        : 112  \n Max.   :5060.0       (Other) : 160   (Other): 406   (Other)  : 232  \n NA's   :21           NA's    :  12   NA's   :   5   NA's     : 303  \n     budget            title_year   actor_2_facebook_likes   imdb_score   \n Min.   :2.180e+02   Min.   :1916   Min.   :     0         Min.   :1.600  \n 1st Qu.:6.000e+06   1st Qu.:1999   1st Qu.:   281         1st Qu.:5.800  \n Median :2.000e+07   Median :2005   Median :   595         Median :6.600  \n Mean   :3.975e+07   Mean   :2002   Mean   :  1652         Mean   :6.442  \n 3rd Qu.:4.500e+07   3rd Qu.:2011   3rd Qu.:   918         3rd Qu.:7.200  \n Max.   :1.222e+10   Max.   :2016   Max.   :137000         Max.   :9.500  \n NA's   :492         NA's   :108    NA's   :13                            \n  aspect_ratio   movie_facebook_likes\n Min.   : 1.18   Min.   :     0      \n 1st Qu.: 1.85   1st Qu.:     0      \n Median : 2.35   Median :   166      \n Mean   : 2.22   Mean   :  7526      \n 3rd Qu.: 2.35   3rd Qu.:  3000      \n Max.   :16.00   Max.   :349000      \n NA's   :329                         \n\n\nFollow-up:\nWhat type of info is provided on quantitative variables? What type of info is provided on categorical variables? What stands out to you in these summaries? Is there anything you’d need to clean before using this data?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Import</span>"
    ]
  },
  {
    "objectID": "ica/ica-data import.html#exercise-4-clean-data-factor-variables-1",
    "href": "ica/ica-data import.html#exercise-4-clean-data-factor-variables-1",
    "title": "\n17  Data Import\n",
    "section": "\n17.4 Exercise 4: Clean Data: Factor Variables 1",
    "text": "17.4 Exercise 4: Clean Data: Factor Variables 1\nIf you didn’t already in Exercise 3, check out the color variable in the imdb_messy dataset.\nWhat’s goofy about this / what do we need to fix? More specifically, what different categories does the color variable take, and how many movies fall into each of these categories?\n\nCodeimdb_messy |&gt; \n  count(color)\n\n# A tibble: 6 × 2\n  color               n\n  &lt;chr&gt;           &lt;int&gt;\n1 B&W                10\n2 Black and White   199\n3 COLOR              30\n4 Color            4755\n5 color              30\n6 &lt;NA&gt;               19",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Import</span>"
    ]
  },
  {
    "objectID": "ica/ica-data import.html#exercise-5-clean-data-factor-variables-2",
    "href": "ica/ica-data import.html#exercise-5-clean-data-factor-variables-2",
    "title": "\n17  Data Import\n",
    "section": "\n17.5 Exercise 5: Clean Data: Factor Variables 2",
    "text": "17.5 Exercise 5: Clean Data: Factor Variables 2\nWhen working with categorical variables like color, the categories must be “clean”, i.e. consistent and in the correct format. Let’s make that happen.\n\n17.5.0.1 Part a\nWe could open the .csv file in, say, Excel or Google sheets, clean up the color variable, save a clean copy, and then reimport that into RStudio. BUT that would be the wrong thing to do. Why is it important to use R code, which we then save inside this qmd, to clean our data?\nSo that other people to come after can follow through, it makes the data reproducible.\n\n17.5.0.2 Part b\nLet’s use R code to change the color variable so that it appropriately combines the various categories into only 2: Color and Black_White. We’ve learned a couple sets of string-related tools that could be handy here. First, starting with the imdb_messy data, change the color variable using one of the functions we learned in the Factors lesson.\nfct_relevel(), fct_recode(), fct_reorder()\nStore your results in imdb_temp (don’t overwrite imdb_messy). To check your work, print out a count() table of the color variable in imdb_temp.\n\nCodeimdb_temp &lt;- imdb_messy |&gt; \n  mutate(color = fct_recode(color,\n                            \"Color\" = \"COLOR\",\n                            \"Color\" = \"color\",\n                            \"Black_White\" = \"B&W\",\n                            \"Black_White\" = \"Black and White\"))\n\nimdb_temp |&gt; \n  count(color)\n\n# A tibble: 3 × 2\n  color           n\n  &lt;fct&gt;       &lt;int&gt;\n1 Black_White   209\n2 Color        4815\n3 &lt;NA&gt;           19\n\n\n\n17.5.0.3 Part c\nRepeat Part b using one of our string functions from the String lesson:\nstr_replace(), str_replace_all(), str_to_lower(), str_sub(), str_length(), str_detect()\n\nCodeimdb_temp &lt;- imdb_messy |&gt; \n  mutate(color = str_replace(color, \"COLOR\", \"Color\"),\n         color = str_replace(color, \"color\", \"Color\"),\n         color = str_replace(color, \"B&W\", \"Black_White\"),\n         color = str_replace(color, \"Black and White\", \"Black_White\"))\n\nimdb_temp |&gt; \n  count(color)\n\n# A tibble: 3 × 2\n  color           n\n  &lt;chr&gt;       &lt;int&gt;\n1 Black_White   209\n2 Color        4815\n3 &lt;NA&gt;           19",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Import</span>"
    ]
  },
  {
    "objectID": "ica/ica-data import.html#exercise-6-clean-data-missing-data-1",
    "href": "ica/ica-data import.html#exercise-6-clean-data-missing-data-1",
    "title": "\n17  Data Import\n",
    "section": "\n17.6 Exercise 6: Clean Data: Missing Data 1",
    "text": "17.6 Exercise 6: Clean Data: Missing Data 1\nThroughout these exercises, you’ve probably noticed that there’s a bunch of missing data. This is encoded as NA (not available) in R. There are a few questions to address about missing data:\nHow many values are missing data? What’s the volume of the missingness? Why are some values missing? What should we do about the missing values? Let’s consider the first 2 questions in this exercise.\n\n17.6.0.1 Part a\nAs a first step, let’s simply understand the volume of NAs. Specifically:\n\nCodenrow(imdb_messy)\n\n[1] 5043\n\nCodecolSums(is.na(imdb_messy))\n\n                     ...1                     color             director_name \n                        0                        19                       104 \n   num_critic_for_reviews                  duration   director_facebook_likes \n                       50                        15                       104 \n   actor_3_facebook_likes              actor_2_name    actor_1_facebook_likes \n                       23                        13                         7 \n                    gross                    genres              actor_1_name \n                      884                         0                         7 \n              movie_title           num_voted_users cast_total_facebook_likes \n                        0                         0                         0 \n             actor_3_name      facenumber_in_poster             plot_keywords \n                       23                        13                       153 \n          movie_imdb_link      num_user_for_reviews                  language \n                        0                        21                        12 \n                  country            content_rating                    budget \n                        5                       303                       492 \n               title_year    actor_2_facebook_likes                imdb_score \n                      108                        13                         0 \n             aspect_ratio      movie_facebook_likes \n                      329                         0 \n\n\n\n17.6.0.2 Part b\nAs a second step, let’s think about why some values are missing. Study the individual observations with NAs carefully. Why do you think they are missing? Are certain films more likely to have more NAs than others?\n\n17.6.0.3 Part c\nConsider a more specific example. Obtain a dataset of movies that are missing data on actor_1_facebook_likes. Then explain why you think there are NAs. HINT: is.na(___)\n\nCodeimdb_messy |&gt; \n  filter(is.na(actor_1_facebook_likes))\n\n# A tibble: 7 × 29\n   ...1 color director_name     num_critic_for_reviews duration\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                              &lt;dbl&gt;    &lt;dbl&gt;\n1  4503 Color Léa Pool                              23       97\n2  4520 Color Harry Gantz                           12      105\n3  4721 Color U. Roberto Romano                      3       80\n4  4838 Color Pan Nalin                             15      102\n5  4946 Color Amal Al-Agroobi                       NA       62\n6  4947 Color Andrew Berends                        12       90\n7  4991 Color Jem Cohen                             12      111\n# ℹ 24 more variables: director_facebook_likes &lt;dbl&gt;,\n#   actor_3_facebook_likes &lt;dbl&gt;, actor_2_name &lt;chr&gt;,\n#   actor_1_facebook_likes &lt;dbl&gt;, gross &lt;dbl&gt;, genres &lt;chr&gt;,\n#   actor_1_name &lt;chr&gt;, movie_title &lt;chr&gt;, num_voted_users &lt;dbl&gt;,\n#   cast_total_facebook_likes &lt;dbl&gt;, actor_3_name &lt;chr&gt;,\n#   facenumber_in_poster &lt;dbl&gt;, plot_keywords &lt;chr&gt;, movie_imdb_link &lt;chr&gt;,\n#   num_user_for_reviews &lt;dbl&gt;, language &lt;chr&gt;, country &lt;chr&gt;, …\n\nCode#documentaries do not have actors",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Import</span>"
    ]
  },
  {
    "objectID": "ica/ica-data import.html#exercise-7-clean-data-missing-data-2",
    "href": "ica/ica-data import.html#exercise-7-clean-data-missing-data-2",
    "title": "\n17  Data Import\n",
    "section": "\n17.7 Exercise 7: Clean Data: Missing Data 2",
    "text": "17.7 Exercise 7: Clean Data: Missing Data 2\nNext, let’s think about what to do about the missing values. There is no perfect or universal approach here. Rather, we must think carefully about…\nWhy the values are missing? What we want to do with our data? What is the impact of removing or replacing missing data on our work / conclusions?\n\n17.7.0.1 Part a\nCalculate the average duration of a film. THINK: How can we deal with the NA’s?\nFollow-up:\nHow are the NAs dealt with here? Did we have to create and save a new dataset in order to do this analysis?\n\n17.7.0.2 Part b\nTry out the drop_na() function:\n\nCode imdb_temp &lt;- drop_na(imdb_messy)\nnrow(imdb_temp)\n\n[1] 3756\n\n\nFollow-up questions:\nWhat did drop_na() do? How many data points are left? 3756 In what situations might this function be a good idea? in situations where you need to work with calculations In what situations might this function be a bad idea? in situations where the presence/absence of NA changes the interpretation of the data.\n\n17.7.0.3 Part c\ndrop_na() removes data points that have any NA values, even if we don’t care about the variable(s) for which data is missing. This can result in losing a lot of data points that do have data on the variables we actually care about! For example, suppose we only want to explore the relationship between film duration and whether it’s in color. Check out a plot:\n\nCode ggplot(imdb_messy, aes(x = duration, fill = color)) + \n   geom_density()\n\n\n\n\n\n\n\nFollow-up:\nCreate a new dataset with only and all movies that have complete info on duration and color. HINT: You could use !i s.na(___) or drop_na() (differently than above) Use this new dataset to create a new and improved plot. How many movies remain in your new dataset? Hence why this is better than using the dataset from part b?\n\nCodeimdb_temp &lt;- imdb_messy |&gt; \n  select(duration, color) |&gt; \n  drop_na()\ndim(imdb_temp)\n\n[1] 5010    2\n\nCodeggplot(imdb_temp, aes(x = duration, fill = color)) +\n  geom_density()\n\n\n\n\n\n\n\n\n17.7.0.4 Part d\nIn some cases, missing data is more non-data than unknown data. For example, the films with NAs for actor_1_facebook_likes actually have 0 Facebook likes–they don’t even have actors! In these cases, we can replace the NAs with a 0. Use the replace_na() function to create a new dataset (imdb_temp) that replaces the NAs in actor_1_facebook_likes with 0. You’ll have to check out the help file for this function.\n\nCodeimdb_temp &lt;- imdb_messy |&gt; \n  mutate(actor_1_facebook_likes =\n         replace_na(actor_1_facebook_likes, 0))\n\nimdb_temp |&gt; \n  summarize(sum(is.na(actor_1_facebook_likes)))\n\n# A tibble: 1 × 1\n  `sum(is.na(actor_1_facebook_likes))`\n                                 &lt;int&gt;\n1                                    0",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Import</span>"
    ]
  }
]